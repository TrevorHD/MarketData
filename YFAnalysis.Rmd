---
title: 'Machine Learning and Stock Market Data'
subtitle: \textit{An Exercise In Predictive Modelling}
author: "Trevor H. Drees"
output:
  pdf_document:
    fig_caption: yes
    toc: true
editor_options: 
  chunk_output_type: console
header-includes:
- \usepackage{float}
- \usepackage{booktabs}
- \usepackage[width = 0.96\textwidth]{caption}
- \usepackage[hang, flushmargin]{footmisc}
urlcolor: blue
---

\setlength{\skip\footins}{0.35in}

```{r setup, include = FALSE}

knitr::opts_chunk$set(echo = FALSE)

# Load libraries
library(MASS)
library(corrplot)
library(plyr)
library(tidyverse)
library(reshape2)
library(knitr)
library(pROC)
library(car)

# Tidy data
source("https://raw.githubusercontent.com/TrevorHD/MarketData/master/YFData.R")

# Set seed for (pseudo) RNG so results can be replicated
RNGkind(sample.kind = "Rounding")
set.seed(93742)

```

# Disclaimer

Trading stocks, ETFs, options, futures, or any other financial assets or derivatives has inherent risks that should be understood before making any substantial investments; it is the investor's responsibility to determine the appropriate level of risk they can safely subject themself to. The contents of this work are not, in any form, meant to serve as investment advice, but rather as exploratory analysis of stock market data with the goal being able to predict changes in future conditions based solely off of conditions at a prior date. As such, the author bears no liability for any damages or losses, realised or unrealised, incurred by the reader should they choose to use the models in these analyses for any sort of investment guidance.

# Introduction

Stock market data can be incredibly difficult to predict from just stock prices alone; changes in value of a particular stock or ETF today, last week, or last month do not necessarily dictate how it will move today. Often, fluctuations in value are instead driven by shifts in investor confidence due to changes in government monetary policy, outlook on a company's so-called "fundamentals", or disruptions in activity of a particular company or sector, among many other possible factors. While a well-diversified portfolio will almost certainly increase in value over the long run without frequent intervention, the ability to predict short-term changes and fluctuations based off market data is incredibly useful to active traders that are less concerned with holding long positions. For investors that hold particular investments over the course of only days or weeks, short-term changes are much more important for deciding when to buy and sell a stock or whether to make a put or call when running options.

Here, we seek to create models that can predict short-term behaviour and whether the market will increase or decrease a) in a given day, using the performance of the previous 5 days and b) in a given week, using the performance of the previous 5 weeks. To inform inform our models, we use data from three major U.S. stock market indices: the S&P 500, NASDAQ Composite, and Dow Jones Industrial Average. For each index and each time interval (daily or weekly), we compare models derived from a variety of classification frameworks, including parametric methods such as logistic regression and discriminant analysis as well as non-parametric methods such as $k$-nearest neighbours and support vector machines.

# Predictive Analysis: S&P 500

## Data

``` {r}

# Split data into training and test set
trainVec <- sample(1:nrow(SPWeekly), size = nrow(SPWeekly)*0.7, replace = FALSE)
SPWeekly <- SPWeekly[SPWeekly$Direction != "Zero", ]
SPWeekly$Direction <- factor(SPWeekly$Direction)
SPWeeklyTrain <- SPWeekly[trainVec, ]
SPWeeklyTest <- SPWeekly[-trainVec, ]

```

``` {r Figure1, fig.height = 4.4, fig.cap = "\\label{fig:Figure1} Correlations bewteen year, volume, percent change, and the various lag variables for the `Weekly` data on the S&P 500. The area of squares below the diagonal are proportional to the absolute value of the corresponding correlation coefficients."}

# Plots of correlations between variables
SPWeekly %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(method = "square", type = "lower", win.asp = 0.7,
         tl.pos = "tp", tl.col = "black")
SPWeekly %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(add = TRUE, method = "number", type = "upper", 
         number.cex = 0.8, col = "black", tl.pos = "n", cl.pos = "n")

```

``` {r Figure2, fig.height = 8, fig.cap = "\\label{fig:Figure2} Plots of S&P 500 weekly percent change against percent change of up to 5 weeks prior. Autocorrelation in weekly percent change corresponding to 1-5 week lag times is shown in the bottom-right panel; dashed blue lines represent the 95% confidence interval for the autocorrelation."}

# Note: excludes the 1 week where market dropped almost 40%
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(SPWeekly$PctChange, SPWeekly$Lag1, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(20, -20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (1-Week Lag)")
plot(SPWeekly$PctChange, SPWeekly$Lag2, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(20, -20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (2-Week Lag)")
plot(SPWeekly$PctChange, SPWeekly$Lag3, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(20, -20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (3-Week Lag)")
plot(SPWeekly$PctChange, SPWeekly$Lag4, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(20, -20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (4-Week Lag)")
plot(SPWeekly$PctChange, SPWeekly$Lag5, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(20, -20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (5-Week Lag)")
acf(SPWeekly$PctChange, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure3, fig.height = 3.9, fig.cap = "\\label{fig:Figure3} Relative value of the S&P 500 over time compared to its 1990 value, as indicated by the black line. The chart on the bottom represents positive (green) and negative (red) weekly percent changes."}

# Check this chart for accuracy, as it doesn't quite match up with the YF chart
par(mar = c(5, 4, 2, 2) + 0.1)
colourList <- replace(rep("green", nrow(SPWeekly)), which(SPWeekly$PctChange < 0), "red")
barplot(abs(SPWeekly$PctChange), col = colourList, border = colourList, ylim = c(0, 50), axes = FALSE)
par(new = TRUE)
totalReturn <- c()
for(i in 1:nrow(SPWeekly)){
  totalReturn <- c(totalReturn, prod((SPWeekly$PctChange[1:i]/100)+1))}
plot(1:nrow(SPWeekly), totalReturn, type = "l", ylim = c(0, 5), xaxt = "n", 
     xlab = NA, ylab = "Proportion of Initial Value")
axis(1, at = 1773*(0:7)/7, labels = seq(1986, 2021, length.out = 8))
title(xlab = "Year")

```

## Parametric Methods

### Logistic Regression

``` {r}

# Function to perform logistic regression and output predictive accuracy
logreg <- function(formula, dataTrain, dataTest, output){
  
  # Fit logistic regression using training data
  glm.fit <- glm(formula, data = dataTrain, family = binomial)
  
  # Classify test data; get posterior probabilities
  glm.probs <- predict(glm.fit, dataTest, type = "response")
  glm.pred <- rep("Down", length(glm.probs))
  glm.pred[glm.probs >= 0.5] <- "Up"
  
  # Confusion matrix of classified observations
  # Must manually add Down row if model never predicts Down
  confMatrix <- table(glm.pred, dataTest$Direction)
  if(nrow(confMatrix) == 1){
    confMatrix <- rbind(c(0, 0), confMatrix)}
  rownames(confMatrix) <- c("[P]Down", "[P]Up")
  colnames(confMatrix) <- c("[O]Down", "[O]Up")
  
  # Overall predictive accuracy
  accuracy <- sum(diag(confMatrix)/sum(confMatrix))
  
  # Sensitivity and specificity
  specificity <- confMatrix[1, 1]/sum(confMatrix[, 1])
  sensitivity <- confMatrix[2, 2]/sum(confMatrix[, 2])
  
  # Positive and negative predictive value
  npv <- confMatrix[1, 1]/sum(confMatrix[1, ])
  ppv <- confMatrix[2, 2]/sum(confMatrix[2, ])
  
  # Return individual outputs or list of all outputs
  if(output == "all"){
    return(list(confMatrix = confMatrix, accuracy = accuracy, specificity = specificity,
              sensitivity = sensitivity, npv = npv, ppv = ppv))}
  if(output == "confMatrix"){
    return(confMatrix)}
  if(output == "accuracy"){
    return(accuracy)}
  if(output == "specificity"){
    return(specificity)}
  if(output == "sensitivity"){
    return(sensitivity)}
  if(output == "npv"){
    return(npv)}
  if(output == "ppv"){
    return(ppv)}}

```

``` {r}

# Function to fit logistic regression to all possible combinations of n variables
# Outputs value and combination of variables for desired prediction metric
logreg.comb <- function(dataTrain, dataTest, output, n){
  combn(names(dataTrain)[-c(1:2)], n) %>% 
    apply(FUN = paste0, MARGIN = 2, collapse = "+") %>% 
    paste0("Direction~", .) %>% 
    sapply(FUN = logreg, dataTrain = dataTrain, dataTest = dataTest, output = output) %>% 
    sort() %>%
    return()}

# Best models for accuracy, sensitivity, specificity, PPV, and NPV
# will clean this section to make it look nicer
test <- unlist(sapply(1:8, FUN = logreg.comb, dataTrain = SPWeeklyTrain,
              dataTest = SPWeeklyTest, output = "accuracy"))
test[test == max(test)]
test <- unlist(sapply(1:8, FUN = logreg.comb, dataTrain = SPWeeklyTrain,
              dataTest = SPWeeklyTest, output = "sensitivity"))
test[test == max(test)]
test <- unlist(sapply(1:8, FUN = logreg.comb, dataTrain = SPWeeklyTrain,
              dataTest = SPWeeklyTest, output = "specificity"))
test[test == max(test)]
test <- unlist(sapply(1:8, FUN = logreg.comb, dataTrain = SPWeeklyTrain,
              dataTest = SPWeeklyTest, output = "ppv"))
test[test == max(test)]
test <- unlist(sapply(1:8, FUN = logreg.comb, dataTrain = SPWeeklyTrain,
              dataTest = SPWeeklyTest, output = "npv"))
test[test == max(test)]

```

### Discriminant Analysis

## Non-Parametric Methods

### K-Nearest Neighbours

### Support Vector Machines

# Predictive Analysis: NASDAQ Composite

## Data

## Parametric Methods

### Logistic Regression

### Discriminant Analysis

## Non-Parametric Methods

### K-Nearest Neighbours

### Support Vector Machines

# Predictive Analysis: Dow Jones Industrial Average

## Data

## Parametric Methods

### Logistic Regression

### Discriminant Analysis

## Non-Parametric Methods

### K-Nearest Neighbours

### Support Vector Machines

# Conclusions
