---
title: 'Machine Learning and Stock Market Data'
subtitle: \textit{An Exercise In Predictive Modelling}
author: "Trevor H. Drees"
output:
  pdf_document:
    fig_caption: yes
    toc: true
editor_options: 
  chunk_output_type: console
header-includes:
- \usepackage{float}
- \usepackage{booktabs}
- \usepackage[width = 0.96\textwidth]{caption}
- \usepackage[hang, flushmargin]{footmisc}
urlcolor: blue
---

\setlength{\skip\footins}{0.35in}

```{r setup, include = FALSE}

# Load libraries
library(MASS)
library(corrplot)
library(plyr)
library(tidyverse)
library(reshape2)
library(knitr)
library(pROC)
library(car)

# Set chunk and hook options
knitr::opts_chunk$set(echo = FALSE, fig.pos = 'htb!')

# Tidy data
source("https://raw.githubusercontent.com/TrevorHD/MarketData/master/YFData.R")

# Set seed for (pseudo) RNG so results can be replicated
set.seed(18361)

```

\newpage

# Disclaimer

Trading stocks, ETFs, options, futures, or any other financial assets or derivatives has inherent risks that should be understood before making any substantial investments; such risks can include significant loss of principal, and it is the investor's responsibility to determine their appropriate level of exposure to risk. The contents of this work are not, in any form, meant to serve as investment advice, but rather as exploratory analysis of stock market data with the goal being able to predict changes in future conditions based solely off of conditions at a prior date. As such, the author bears no liability for any damages or losses, realised or unrealised, incurred by the reader should they choose to use the models in these analyses for any sort of investment guidance.

# Introduction

Stock market data can be incredibly difficult to predict from just stock prices alone; changes in value of a particular stock or ETF today, last week, or last month do not necessarily dictate how it will move today. Often, fluctuations in value are instead driven by shifts in investor confidence due to changes in government monetary policy, outlook on a company's so-called "fundamentals", or disruptions in activity of a particular company or sector, among many other possible factors. While a well-diversified portfolio will almost certainly increase in value over the long run without frequent intervention, the ability to predict short-term changes and fluctuations based off market data is incredibly useful to active traders that are less concerned with holding long positions. For investors that hold particular investments over the course of only days or weeks, short-term changes are much more important for deciding when to buy and sell a stock or whether to make a put or call when trading options.

Here, we seek to create models that can predict short-term market behaviour, as such a model would be a very valuable investment tool for traders. More specifically, seek to be able to predict whether the market will increase or decrease a) in a given day, using the performance of the previous 5 trading days and b) in a given week, using the performance of the previous 5 weeks (25 trading days). To inform inform our models, we use data from three major U.S. stock market indices: the S&P 500, NASDAQ Composite, and Dow Jones Industrial Average. For each index and each timeframe, we compare models derived from a variety of classification frameworks, including parametric methods such as logistic regression and discriminant analysis as well as non-parametric methods such as $k$-nearest neighbours and support vector machines. We also discuss possible trading strategies based on model attributes such as overall accuracy, sensitivity, specificity, and positive and negative predictive value.

# Data

We first start by introducing and briefly exploring the six data sets that will be used in these analyses. First, we have `SPDaily` and `SPWeekly`, which are daily and weekly data (respectively) on the S&P 500, a major stock market index consisting of 500 publicly-traded American companies. Next, we have `NDDaily` and `NDWeekly`, which are daily and weekly data (respectively) on the NASDAQ Composite, another major stock market index that is largely weighted on the information technology sector. Finally, we have `DJDaily` and `DJWeekly`, which are daily and weekly data (respectively) on the NASDAQ Composite, a major stock market index that consisting of 30 large American companies from a variety of different market sectors. All data, which are available online from Yahoo Finance[^FootNote1], were scraped in Python using the `yfinance` packeage and stored in six different CSV files; weekly/daily percent change was then calculated using the opening and closing prices for a particular week/day, and lagged up to 5 weeks/days. The total and average percent change over a 5-week or 5-day period were also calculated. The variables in our new datasets are listed below:

* **BVolume**: average number of daily shares traded (billions)
* **PctChange**: percent change for a given week/day
* **Direction**: whether the percent change for a given week/day was negative or positive
* **Prev5GM**: Average ()geometric mean) percent increase over the previous 5 weeks/days
* **Prev5Pct**: Total percent increase over the previous 5 weeks/days
* **Lag1**: 1-week lag on percent change for a given week/day
* **Lag2**: 2-week lag on percent change for a given week/day
* **Lag3**: 3-week lag on percent change for a given week/day
* **Lag4**: 4-week lag on percent change for a given week/day
* **Lag5**: 5-week lag on percent change for a given week/day
* **VLag1**: 1-week lag on volume for a given week/day
* **VLag2**: 2-week lag on volume for a given week/day
* **VLag3**: 3-week lag on volume for a given week/day
* **VLag4**: 4-week lag on volume for a given week/day
* **VLag5**: 5-week lag on volume for a given week/day

Note that for the `SPDaily`, `NDDaily`, and `DJDaily` datasets, all calculations and quantities are in terms of days rather than weeks; for the `SPWeekly`, `NDWeekly`, and `DJWeekly` datasets, all calculations and quantities are in terms of weeks rather than days. For example, the `Lag2` variable would represent the percent change two days ago in the `SPDaily` dataset, but would represent the percent change two weeks ago in the `SPWeekly` dataset.

We first conduct some exploratory analyses of the data to see if there are any patterns that need attention or may be important for our analyses, starting with the S&P 500 daily and weekly data. Upon examining the correlation matrices and heatmaps shown in Figure \ref{fig:Figure1}, there seems to be several strong correlations. The strong positive correlation between `Direction` and `PctChange` is not surprising, given that `Direction` is literally defined by whether the percent change is negative or positive. Though we would thus expect there to be a perfect relationship between the two variables, and indeed there is, it does not translate well to a linear correlation. We also see that `Prev5GM` and `Prev5Pct` have a correlation of 1; this is because the total percent increase over the previous 5 weeks can also be found by exponentiating the average percent increase to the fifth power. Thus, there is an obvious relationship between the two variables, and any models containing the both may experience multicollinearity issues. These same trends can also be seen in the NASDAQ data (Figure \ref{fig:Figure2}) and the Dow Jones data (Figure \ref{fig:Figure3}).

Another thing worth pointing out in Figure \ref{fig:Figure1} is that `Direction`, the variable that we're interested in predicting, bears almost no correlation with `Prev5GM`, `Prev5Pct`, or any of the `Lag` variables; this may be problematic when trying to make predictions. Figure \ref{fig:Figure4} provides further evidence of this on the S&P 500 weekly data and Figure \ref{fig:Figure5} on the S&P 500 daily data, focusing specifically on the lack of correlation between percent change and the five lag variables. Here, we see that there is almost no autocorrelation of percent change in a given week; that is, percent change in a given week is not strongly correlated with percent change in any of the five weeks before. This observation may be bad news for our analyses later: if there is not much of an association between percent change in a given week and percent change in any of the weeks before it, then how can we use past weekly performance to accurately predict future weekly performance? While there is no apparent autocorrelation in returns for the S&P 500, there does seem to be an autocorrelation in trading volume, as is evident in Figures \ref{fig:Figure6} and \ref{fig:Figure7}.

Unsurprisingly, we also see the exact same lack of autocorrelation in returns and strong autocorrelation in trading volume for both the NASDAQ and Dow Jones data. Figures \ref{fig:Figure8} and \ref{fig:Figure9} demonstrate a lack of autocorrelation in NASDAQ daily and weekly returns, while Figures \ref{fig:Figure10} and \ref{fig:Figure11} show that daily and weekly volume is strongly autocorrelated; likewise, Figures \ref{fig:Figure12} and \ref{fig:Figure13} also demonstrate a lack of autocorrelation in Dow Jones daily and weekly returns, while Figures \ref{fig:Figure14} and \ref{fig:Figure15} again show that daily and weekly volume is strongly autocorrelated.

Separating the S&P 500 data based on the value of `Direction` allows us to further explore trends in increases and decreases. For example, upon doing so, we see that the mean weekly percent decrease on the S&P 500 is -1.81%, while the mean weekly increase is 1.67%; however, even though the average magnitude of weekly percent decreases is higher than that of weekly percent increases, the number of weeks in which there was an increase is greater than the number of weeks in which there was a decrease (1041 versus 784). If we look at the data in terms of days instead, we find that there are again more increases than decreases, with 4063 negative days with a mean daily decrease of -0.752% and 4750 positive days with a mean daily increase of 0.707%; this difference is noticable in the bottom panel of Figure \ref{fig:Figure16}. The fact that there are more positive than negative days/weeks is likely responsible for the trend shown in the top panel of Figure \ref{fig:Figure16} where, despite plummeting several times (e.g. two recessions in the 2000's and the COVID-related plunge in early 2020) and suffering numerous smaller drops, the S&P 500 was still almost 14 times as high in 2021 as it was in 1986.

Again, we see the same trends in the NASDAQ and Dow Jones data if we separate it based on `Direction`. The NASDAQ has 772 negative weeks with a mean weekly decrease of -2.36% and 1052 positive weeks with a mean weekly increase of 2.04%; when broken into days, there 4000 negative days with a mean daily decrease of -0.849% and 4776 positive days with a mean daily increase of 0.724%. This difference is noticable in the bottom panel of Figure \ref{fig:Figure17} and is likely responsible for the increase in value over time, despite the massive crash in 2000 from the Dot-Com Bubble. If we look at the Dow Jones, we see that it has 643 negative weeks with a mean weekly decrease of -1.64% and 866 positive weeks with a mean weekly increase of 1.53%; when broken into days, there 3383 negative days with a mean daily decrease of -0.728% and 3913 positive days with a mean daily increase of 0.696%. This difference is again noticable in the bottom panel of Figure \ref{fig:Figure18} and is also likely responsible for the increase in value over time. Note that because the Yahoo Finance data on the Dow Jones only starts in 1992 (though the Dow Jones has been around much longer than that), we have less data to work with than we do for the S&P 500 and NASDAQ.

We now move forward with our analyses, keeping in mind that the lack of autocorrelation in weekly percent change may make it difficult to accurately construct models that use past percentage changes to predict future S&P 500 movements. However, there is some good news: because there is only a slight difference in the number of positive and negative days/weeks, we do not have to worry about predicting a small number of observations in a highly-skewed data set, and thus face fewer restrictions with the tools and algorithms we plan on using. Before we begin, we split each of our data sets into a training set with observations from 1986-2010 and a test set with the remaining observations from 2011-2021; this validation set approach will allows us to fit models on the training data and then examine their performance on the test data, reducing the chances of overfitting the data. We also drop the variables `VLag1` through `VLag5`, as preliminary analyses (not shown in this report) indicate that these variables make almost no difference when constructing our models.

[^FootNote1]: S&P 500 data can be found [here](https://finance.yahoo.com/quote/%5EGSPC/history?p=%5EGSPC), NASDAQ Composite data can be found [here](https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC), and Dow Jones Industrial Data can be found [here](https://finance.yahoo.com/quote/%5EDJI/history?p=%5EDJI). Data last accessed on 26 March 2021.

``` {r include = FALSE}

# Counts and means for S&P 500 decreases/increases
SPWeekly %>% group_by(Direction) %>% 
  summarise(Count = n(),
            Change = mean(PctChange))
SPDaily %>% group_by(Direction) %>% 
  summarise(Count = n(),
            Change = mean(PctChange))

# Split S&P 500 data into training and test sets
#trainVec <- sample(1:nrow(SPWeekly), size = nrow(SPWeekly)*0.7, replace = FALSE)
trainVec <- 1:(25*52)
SPWeekly <- SPWeekly[SPWeekly$Direction != "Zero", ]
SPWeekly$Direction <- factor(SPWeekly$Direction)
SPWeeklyTrain <- SPWeekly[trainVec, ]
SPWeeklyTest <- SPWeekly[-trainVec, ]
#trainVec <- sample(1:nrow(SPDaily), size = nrow(SPDaily)*0.7, replace = FALSE)
#SPDaily <- SPDaily[SPDaily$Direction != "Zero", ]
#SPDaily$Direction <- factor(SPDaily$Direction)
#SPDailyTrain <- SPDaily[trainVec, ]
#SPDailyTest <- SPDaily[-trainVec, ]

# Counts and means for NASDAQ decreases/increases
NDWeekly %>% group_by(Direction) %>% 
  summarise(Count = n(),
            Change = mean(PctChange))
NDDaily %>% group_by(Direction) %>% 
  summarise(Count = n(),
            Change = mean(PctChange))

# Split NASDAQ data into training and test sets
#trainVec <- sample(1:nrow(NDWeekly), size = nrow(NDWeekly)*0.7, replace = FALSE)
NDWeekly <- NDWeekly[NDWeekly$Direction != "Zero", ]
NDWeekly$Direction <- factor(NDWeekly$Direction)
NDWeeklyTrain <- NDWeekly[trainVec, ]
NDWeeklyTest <- NDWeekly[-trainVec, ]
#trainVec <- sample(1:nrow(NDDaily), size = nrow(NDDaily)*0.7, replace = FALSE)
#NDDaily <- NDDaily[NDDaily$Direction != "Zero", ]
#NDDaily$Direction <- factor(NDDaily$Direction)
#NDDailyTrain <- NDDaily[trainVec, ]
#NDDailyTest <- NDDaily[-trainVec, ]

# Counts and means for Dow Jones decreases/increases
DJWeekly %>% group_by(Direction) %>% 
  summarise(Count = n(),
            Change = mean(PctChange))
DJDaily %>% group_by(Direction) %>% 
  summarise(Count = n(),
            Change = mean(PctChange))

# Split Dow Jones data into training and test sets
#trainVec <- sample(1:nrow(DJWeekly), size = nrow(DJWeekly)*0.7, replace = FALSE)
trainVec <- 1:(19*52)
DJWeekly <- DJWeekly[DJWeekly$Direction != "Zero", ]
DJWeekly$Direction <- factor(DJWeekly$Direction)
DJWeeklyTrain <- DJWeekly[trainVec, ]
DJWeeklyTest <- DJWeekly[-trainVec, ]
#trainVec <- sample(1:nrow(DJDaily), size = nrow(DJDaily)*0.7, replace = FALSE)
#DJDaily <- DJDaily[DJDaily$Direction != "Zero", ]
#DJDaily$Direction <- factor(DJDaily$Direction)
#DJDailyTrain <- DJDaily[trainVec, ]
#DJDailyTest <- DJDaily[-trainVec, ]

# Remove trainvec from global environment
remove(trainVec)

```

``` {r Figure1, fig.height = 8, fig.cap = "\\label{fig:Figure1} Correlations bewteen volume, percent change, and the various lag variables for the weekly (top) and daily (bottom) data on the S\\&P 500. The area of squares below the diagonal are proportional to the absolute value of the corresponding correlation coefficients."}

# Plots of correlations between variables: weekly data
par(mfrow = c(2, 1), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
SPWeekly %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(method = "square", type = "lower", win.asp = 0.7, tl.cex = 0.7,
         tl.pos = "tp", tl.col = "black")
SPWeekly %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(add = TRUE, method = "number", type = "upper", 
         number.cex = 0.5, col = "black", tl.pos = "n", cl.pos = "n")

# Plots of correlations between variables: daily data
par(mar = c(5, 4, 0, 2) + 0.1)
SPDaily %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(method = "square", type = "lower", win.asp = 0.7, tl.cex = 0.7,
         tl.pos = "tp", tl.col = "black")
SPDaily %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(add = TRUE, method = "number", type = "upper", 
         number.cex = 0.5, col = "black", tl.pos = "n", cl.pos = "n")

```

``` {r Figure2, fig.height = 8, fig.cap = "\\label{fig:Figure2} Correlations bewteen volume, percent change, and the various lag variables for the weekly (top) and daily (bottom) data on the NASDAQ Composite. The area of squares below the diagonal are proportional to the absolute value of the corresponding correlation coefficients."}

# Plots of correlations between variables: weekly data
par(mfrow = c(2, 1), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
NDWeekly %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(method = "square", type = "lower", win.asp = 0.7, tl.cex = 0.7,
         tl.pos = "tp", tl.col = "black")
NDWeekly %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(add = TRUE, method = "number", type = "upper", 
         number.cex = 0.5, col = "black", tl.pos = "n", cl.pos = "n")

# Plots of correlations between variables: daily data
par(mar = c(5, 4, 0, 2) + 0.1)
NDDaily %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(method = "square", type = "lower", win.asp = 0.7, tl.cex = 0.7,
         tl.pos = "tp", tl.col = "black")
NDDaily %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(add = TRUE, method = "number", type = "upper", 
         number.cex = 0.5, col = "black", tl.pos = "n", cl.pos = "n")

```

``` {r Figure3, fig.height = 8, fig.cap = "\\label{fig:Figure3} Correlations bewteen volume, percent change, and the various lag variables for the weekly (top) and daily (bottom) data on the Dow Jones Industrial Average. The area of squares below the diagonal are proportional to the absolute value of the corresponding correlation coefficients."}

# Plots of correlations between variables: weekly data
par(mfrow = c(2, 1), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
DJWeekly %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(method = "square", type = "lower", win.asp = 0.7, tl.cex = 0.7,
         tl.pos = "tp", tl.col = "black")
DJWeekly %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(add = TRUE, method = "number", type = "upper", 
         number.cex = 0.5, col = "black", tl.pos = "n", cl.pos = "n")

# Plots of correlations between variables: daily data
par(mar = c(5, 4, 0, 2) + 0.1)
DJDaily %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(method = "square", type = "lower", win.asp = 0.7, tl.cex = 0.7,
         tl.pos = "tp", tl.col = "black")
DJDaily %>% mutate(Direction = ifelse(Direction == "Up", 1, 0)) %>% cor() %>% 
corrplot(add = TRUE, method = "number", type = "upper", 
         number.cex = 0.5, col = "black", tl.pos = "n", cl.pos = "n")

```

``` {r Figure4, fig.height = 8, fig.cap = "\\label{fig:Figure4} Plots of S\\&P 500 weekly percent change against percent change of up to 5 weeks prior. Autocorrelation in daily percent change corresponding to 1-5 day lag times is shown in the bottom-right panel; dashed blue lines represent the 95\\% confidence interval for the autocorrelation."}

# Plot percent change for given week against percent change up to five weeks ago
# Also plot autocorrelation in percent change
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(SPWeekly$PctChange, SPWeekly$Lag1, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (1-Week Lag)")
plot(SPWeekly$PctChange, SPWeekly$Lag2, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (2-Week Lag)")
plot(SPWeekly$PctChange, SPWeekly$Lag3, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (3-Week Lag)")
plot(SPWeekly$PctChange, SPWeekly$Lag4, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (4-Week Lag)")
plot(SPWeekly$PctChange, SPWeekly$Lag5, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (5-Week Lag)")
acf(SPWeekly$PctChange, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure5, fig.height = 8, fig.cap = "\\label{fig:Figure5} Plots of S\\&P 500 daily percent change against percent change of up to 5 days prior. Autocorrelation in daily percent change corresponding to 1-5 day lag times is shown in the bottom-right panel; dashed blue lines represent the 95\\% confidence interval for the autocorrelation."}

# Plot percent change for given day against percent change up to five days ago
# Also plot autocorrelation in percent change
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(SPDaily$PctChange, SPDaily$Lag1, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (1-Day Lag)")
plot(SPDaily$PctChange, SPDaily$Lag2, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (2-Day Lag)")
plot(SPDaily$PctChange, SPDaily$Lag3, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (3-Day Lag)")
plot(SPDaily$PctChange, SPDaily$Lag4, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (4-Day Lag)")
plot(SPDaily$PctChange, SPDaily$Lag5, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (5-Day Lag)")
acf(SPDaily$PctChange, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure6, fig.height = 8, fig.cap = "\\label{fig:Figure6} Plots of S\\&P 500 weekly volume against volume of up to 5 weeks prior. Autocorrelation in volume corresponding to 1-5 week lag times is shown in the bottom-right panel; dashed blue lines represent the 95\\% confidence interval for the autocorrelation."}

# Plot volume for given week against volume up to five weeks ago
# Also plot autocorrelation in volume
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(SPWeekly$BVolume, SPWeekly$VLag1, xlim = c(0, 40), xlab = "Volume", ylim = c(0, 40),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (1-Week Lag)")
plot(SPWeekly$BVolume, SPWeekly$VLag2, xlim = c(0, 40), xlab = "Volume", ylim = c(0, 40),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (2-Week Lag)")
plot(SPWeekly$BVolume, SPWeekly$VLag3, xlim = c(0, 40), xlab = "Volume", ylim = c(0, 40),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (3-Week Lag)")
plot(SPWeekly$BVolume, SPWeekly$VLag4, xlim = c(0, 40), xlab = "Volume", ylim = c(0, 40),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (4-Week Lag)")
plot(SPWeekly$BVolume, SPWeekly$VLag5, xlim = c(0, 40), xlab = "Volume", ylim = c(0, 40),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (5-Week Lag)")
acf(SPWeekly$BVolume, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure7, fig.height = 8, fig.cap = "\\label{fig:Figure7} Plots of S\\&P 500 daily volume against volume of up to 5 days prior. Autocorrelation in volume corresponding to 1-5 day lag times is shown in the bottom-right panel; dashed blue lines represent the 95\\% confidence interval for the autocorrelation."}

# Plot volume for given day against volume up to five days ago
# Also plot autocorrelation in volume
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(SPDaily$BVolume, SPDaily$VLag1, xlim = c(0, 12), xlab = "Volume", ylim = c(0, 12),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (1-Day Lag)")
plot(SPDaily$BVolume, SPDaily$VLag2, xlim = c(0, 12), xlab = "Volume", ylim = c(0, 12),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (2-Day Lag)")
plot(SPDaily$BVolume, SPDaily$VLag3, xlim = c(0, 12), xlab = "Volume", ylim = c(0, 12),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (3-Day Lag)")
plot(SPDaily$BVolume, SPDaily$VLag4, xlim = c(0, 12), xlab = "Volume", ylim = c(0, 12),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (4-Day Lag)")
plot(SPDaily$BVolume, SPDaily$VLag5, xlim = c(0, 12), xlab = "Volume", ylim = c(0, 12),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (5-Day Lag)")
acf(SPDaily$BVolume, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure8, fig.height = 8, fig.cap = "\\label{fig:Figure8} Plots of NASDAQ Composite weekly percent change against percent change of up to 5 weeks prior. Autocorrelation in weekly percent change corresponding to 1-5 week lag times is shown in the bottom-right panel; dashed blue lines represent the 95\\% confidence interval for the autocorrelation."}

# Plot percent change for given week against percent change up to five weeks ago
# Also plot autocorrelation in percent change
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(NDWeekly$PctChange, NDWeekly$Lag1, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (1-Week Lag)")
plot(NDWeekly$PctChange, NDWeekly$Lag2, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (2-Week Lag)")
plot(NDWeekly$PctChange, NDWeekly$Lag3, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (3-Week Lag)")
plot(NDWeekly$PctChange, NDWeekly$Lag4, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (4-Week Lag)")
plot(NDWeekly$PctChange, NDWeekly$Lag5, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (5-Week Lag)")
acf(NDWeekly$PctChange, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure9, fig.height = 8, fig.cap = "\\label{fig:Figure9} Plots of NASDAQ Composite daily percent change against percent change of up to 5 days prior. Autocorrelation in daily percent change corresponding to 1-5 day lag times is shown in the bottom-right panel; dashed blue lines represent the 95\\% confidence interval for the autocorrelation."}

# Plot percent change for given day against percent change up to five days ago
# Also plot autocorrelation in percent change
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(NDDaily$PctChange, NDDaily$Lag1, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (1-Day Lag)")
plot(NDDaily$PctChange, NDDaily$Lag2, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (2-Day Lag)")
plot(NDDaily$PctChange, NDDaily$Lag3, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (3-Day Lag)")
plot(NDDaily$PctChange, NDDaily$Lag4, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (4-Day Lag)")
plot(NDDaily$PctChange, NDDaily$Lag5, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (5-Day Lag)")
acf(NDDaily$PctChange, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure10, fig.height = 8, fig.cap = "\\label{fig:Figure10} Plots of NASDAQ Composite weekly volume against volume of up to 5 weeks prior. Autocorrelation in volume corresponding to 1-5 week lag times is shown in the bottom-right panel; dashed blue lines represent the 95\\% confidence interval for the autocorrelation."}

# Plot volume for given week against volume up to five weeks ago
# Also plot autocorrelation in volume
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(NDWeekly$BVolume, NDWeekly$VLag1, xlim = c(0, 28), xlab = "Volume", ylim = c(0, 28),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (1-Week Lag)")
plot(NDWeekly$BVolume, NDWeekly$VLag2, xlim = c(0, 28), xlab = "Volume", ylim = c(0, 28),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (2-Week Lag)")
plot(NDWeekly$BVolume, NDWeekly$VLag3, xlim = c(0, 28), xlab = "Volume", ylim = c(0, 28),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (3-Week Lag)")
plot(NDWeekly$BVolume, NDWeekly$VLag4, xlim = c(0, 28), xlab = "Volume", ylim = c(0, 28),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (4-Week Lag)")
plot(NDWeekly$BVolume, NDWeekly$VLag5, xlim = c(0, 28), xlab = "Volume", ylim = c(0, 28),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (5-Week Lag)")
acf(NDWeekly$BVolume, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure11, fig.height = 8, fig.cap = "\\label{fig:Figure11} Plots of NASDAQ Composite daily volume against volume of up to 5 days prior. Autocorrelation in volume corresponding to 1-5 day lag times is shown in the bottom-right panel; dashed blue lines represent the 95\\% confidence interval for the autocorrelation."}

# Plot volume for given day against volume up to five days ago
# Also plot autocorrelation in volume
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(NDDaily$BVolume, NDDaily$VLag1, xlim = c(0, 8), xlab = "Volume", ylim = c(0, 8),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (1-Day Lag)")
plot(NDDaily$BVolume, NDDaily$VLag2, xlim = c(0, 8), xlab = "Volume", ylim = c(0, 8),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (2-Day Lag)")
plot(NDDaily$BVolume, NDDaily$VLag3, xlim = c(0, 8), xlab = "Volume", ylim = c(0, 8),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (3-Day Lag)")
plot(NDDaily$BVolume, NDDaily$VLag4, xlim = c(0, 8), xlab = "Volume", ylim = c(0, 8),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (4-Day Lag)")
plot(NDDaily$BVolume, NDDaily$VLag5, xlim = c(0, 8), xlab = "Volume", ylim = c(0, 8),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (5-Day Lag)")
acf(NDDaily$BVolume, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure12, fig.height = 8, fig.cap = "\\label{fig:Figure12} Plots of Dow Jones Industrial Average weekly percent change against percent change of up to 5 weeks prior. Autocorrelation in weekly percent change corresponding to 1-5 week lag times is shown in the bottom-right panel; dashed blue lines represent the 95\\% confidence interval for the autocorrelation."}

# Plot percent change for given week against percent change up to five weeks ago
# Also plot autocorrelation in percent change
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(DJWeekly$PctChange, DJWeekly$Lag1, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (1-Week Lag)")
plot(DJWeekly$PctChange, DJWeekly$Lag2, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (2-Week Lag)")
plot(DJWeekly$PctChange, DJWeekly$Lag3, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (3-Week Lag)")
plot(DJWeekly$PctChange, DJWeekly$Lag4, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (4-Week Lag)")
plot(DJWeekly$PctChange, DJWeekly$Lag5, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (5-Week Lag)")
acf(DJWeekly$PctChange, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure13, fig.height = 8, fig.cap = "\\label{fig:Figure13} Plots of Dow Jones Industrial Average daily percent change against percent change of up to 5 days prior. Autocorrelation in daily percent change corresponding to 1-5 day lag times is shown in the bottom-right panel; dashed blue lines represent the 95\\% confidence interval for the autocorrelation."}

# Plot percent change for given day against percent change up to five days ago
# Also plot autocorrelation in percent change
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(DJDaily$PctChange, DJDaily$Lag1, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (1-Day Lag)")
plot(DJDaily$PctChange, DJDaily$Lag2, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (2-Day Lag)")
plot(DJDaily$PctChange, DJDaily$Lag3, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (3-Day Lag)")
plot(DJDaily$PctChange, DJDaily$Lag4, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (4-Day Lag)")
plot(DJDaily$PctChange, DJDaily$Lag5, xlim = c(-20, 20), xlab = "Percent Change", ylim = c(-20, 20),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Percent Change (5-Day Lag)")
acf(DJDaily$PctChange, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure14, fig.height = 8, fig.cap = "\\label{fig:Figure14} Plots of Dow Jones Industrial Average weekly volume against volume of up to 5 weeks prior. Autocorrelation in volume corresponding to 1-5 week lag times is shown in the bottom-right panel; dashed blue lines represent the 95\\% confidence interval for the autocorrelation."}

# Plot volume for given week against volume up to five weeks ago
# Also plot autocorrelation in volume
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(DJWeekly$BVolume, DJWeekly$VLag1, xlim = c(0, 0.04), xlab = "Volume", ylim = c(0, 0.04),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (1-Week Lag)")
plot(DJWeekly$BVolume, DJWeekly$VLag2, xlim = c(0, 0.04), xlab = "Volume", ylim = c(0, 0.04),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (2-Week Lag)")
plot(DJWeekly$BVolume, DJWeekly$VLag3, xlim = c(0, 0.04), xlab = "Volume", ylim = c(0, 0.04),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (3-Week Lag)")
plot(DJWeekly$BVolume, DJWeekly$VLag4, xlim = c(0, 0.04), xlab = "Volume", ylim = c(0, 0.04),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (4-Week Lag)")
plot(DJWeekly$BVolume, DJWeekly$VLag5, xlim = c(0, 0.04), xlab = "Volume", ylim = c(0, 0.04),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (5-Week Lag)")
acf(DJWeekly$BVolume, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure15, fig.height = 8, fig.cap = "\\label{fig:Figure15} Plots of Dow Jones Industrial Average daily volume against volume of up to 5 days prior. Autocorrelation in volume corresponding to 1-5 day lag times is shown in the bottom-right panel; dashed blue lines represent the 95\\% confidence interval for the autocorrelation."}

# Plot volume for given day against volume up to five days ago
# Also plot autocorrelation in volume
par(mfrow = c(3, 2), mar = c(4, 4, 2, 2) + 0.1)
plot(DJDaily$BVolume, DJDaily$VLag1, xlim = c(0, 0.008), xlab = "Volume", ylim = c(0, 0.008),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (1-Day Lag)")
plot(DJDaily$BVolume, DJDaily$VLag2, xlim = c(0, 0.008), xlab = "Volume", ylim = c(0, 0.008),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (2-Day Lag)")
plot(DJDaily$BVolume, DJDaily$VLag3, xlim = c(0, 0.008), xlab = "Volume", ylim = c(0, 0.008),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (3-Day Lag)")
plot(DJDaily$BVolume, DJDaily$VLag4, xlim = c(0, 0.008), xlab = "Volume", ylim = c(0, 0.008),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (4-Day Lag)")
plot(DJDaily$BVolume, DJDaily$VLag5, xlim = c(0, 0.008), xlab = "Volume", ylim = c(0, 0.008),
     col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylab = "Volume (5-Day Lag)")
acf(DJDaily$BVolume, lag.max = 5, lwd = 4, main = NA, xlab = "Lag (Weeks)",
    ylab = "Autocorrelation")
par(mfrow = c(1, 1))

```

``` {r Figure16, fig.height = 7.9, fig.cap = "\\label{fig:Figure16} Relative value of the S\\&P 500 over time compared to its 1986 value (top) and distribution of daily percent changes (bottom). Note that in the bottom panel, the leftmost bin represents all days with a percent change less than -5, and rightmost bin represents all days with a percent change greater than 5. Note that the top chart does not account for after-hours gains or losses."}

# Plot value of S&P 500 over time relative to a 1986 baseline
# Check this chart for accuracy, as it doesn't quite match up with the YF chart
# Discrepancies possibly due to after-hours trading?
par(mfrow = c(2, 1), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
colourList <- replace(rep("green", nrow(SPWeekly)), which(SPWeekly$PctChange < 0), "red")
barplot(abs(SPWeekly$PctChange), col = colourList, border = colourList, ylim = c(0, 50), axes = FALSE)
par(new = TRUE)
totalReturn <- c()
for(i in 1:nrow(SPWeekly)){
  totalReturn <- c(totalReturn, prod((SPWeekly$PctChange[1:i]/100)+1))}
plot(1:nrow(SPWeekly), totalReturn, type = "l", ylim = c(0, 20), xaxt = "n", 
     xlab = NA, ylab = "Proportion of Initial Value")
axis(1, at = nrow(SPWeekly)*(0:7)/7, labels = seq(1986, 2021, length.out = 8))
title(xlab = "Year")

# Plot frequency of daily percent changes
labelvec <- (-11:11)/2
labelvec[labelvec %% 1 == 0.5] <- NA;
SPDaily %>% mutate(PctChange = ifelse(PctChange < -5, -5.1,
                                      ifelse(PctChange > 5, 5.1, PctChange))) %>%
  select(PctChange) %>%
  as.matrix() %>%
  as.vector() %>% 
  hist(x = ., breaks = (-11:11)/2, main = NA, xaxt = "n", xlab = "Daily Percent Change",
       col = c(colorRampPalette(c("red4", "red"), 0.5)(11), colorRampPalette(c("green", "green4"))(11)))
axis(1, at = (-11:11)/2, labels = labelvec)
box()

```

``` {r Figure17, fig.height = 7.9, fig.cap = "\\label{fig:Figure17} Relative value of the NASDAQ Composite over time compared to its 1986 value (top) and distribution of daily percent changes (bottom). Note that in the bottom panel, the leftmost bin represents all days with a percent change less than -5, and rightmost bin represents all days with a percent change greater than 5. Note that the top chart does not account for after-hours gains or losses."}

# Plot value of NASDAQ over time relative to a 1986 baseline
# Check this chart for accuracy, as it doesn't quite match up with the YF chart
# Discrepancies possibly due to after-hours trading?
par(mfrow = c(2, 1), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
colourList <- replace(rep("green", nrow(NDWeekly)), which(NDWeekly$PctChange < 0), "red")
barplot(abs(NDWeekly$PctChange), col = colourList, border = colourList, ylim = c(0, 50), axes = FALSE)
par(new = TRUE)
totalReturn <- c()
for(i in 1:nrow(NDWeekly)){
  totalReturn <- c(totalReturn, prod((NDWeekly$PctChange[1:i]/100)+1))}
plot(1:nrow(NDWeekly), totalReturn, type = "l", ylim = c(0, 12), xaxt = "n", 
     xlab = NA, ylab = "Proportion of Initial Value")
axis(1, at = nrow(NDWeekly)*(0:7)/7, labels = seq(1986, 2021, length.out = 8))
title(xlab = "Year")

# Plot frequency of daily percent changes
labelvec <- (-11:11)/2
labelvec[labelvec %% 1 == 0.5] <- NA;
NDDaily %>% mutate(PctChange = ifelse(PctChange < -5, -5.1,
                                      ifelse(PctChange > 5, 5.1, PctChange))) %>%
  select(PctChange) %>%
  as.matrix() %>%
  as.vector() %>% 
  hist(x = ., breaks = (-11:11)/2, main = NA, xaxt = "n", xlab = "Daily Percent Change",
       col = c(colorRampPalette(c("red4", "red"), 0.5)(11), colorRampPalette(c("green", "green4"))(11)))
axis(1, at = (-11:11)/2, labels = labelvec)
box()

```

``` {r Figure18, fig.height = 7.9, fig.cap = "\\label{fig:Figure18} Relative value of the Dow Jones Industrial Average over time compared to its 1992 value (top) and distribution of daily percent changes (bottom). Note that in the bottom panel, the leftmost bin represents all days with a percent change less than -5, and rightmost bin represents all days with a percent change greater than 5. Note that the top chart does not account for after-hours gains or losses."}

# Plot value of Dow Jones over time relative to a 1986 baseline
# Check this chart for accuracy, as it doesn't quite match up with the YF chart
# Discrepancies possibly due to after-hours trading?
par(mfrow = c(2, 1), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
colourList <- replace(rep("green", nrow(DJWeekly)), which(DJWeekly$PctChange < 0), "red")
barplot(abs(c(rep(0, 316), DJWeekly$PctChange)), col = colourList, border = colourList, ylim = c(0, 50), axes = FALSE)
par(new = TRUE)
totalReturn <- c()
for(i in 1:nrow(DJWeekly)){
  totalReturn <- c(totalReturn, prod((DJWeekly$PctChange[1:i]/100)+1))}
plot((nrow(SPWeekly) - nrow(DJWeekly) + 1):nrow(SPWeekly), totalReturn, type = "l", xlim = c(0, 1825), ylim = c(0, 12), xaxt = "n", 
     xlab = NA, ylab = "Proportion of Initial Value")
axis(1, at = nrow(SPWeekly)*(0:7)/7, labels = seq(1986, 2021, length.out = 8))
title(xlab = "Year")

# Plot frequency of daily percent changes
labelvec <- (-11:11)/2
labelvec[labelvec %% 1 == 0.5] <- NA;
DJDaily %>% mutate(PctChange = ifelse(PctChange < -5, -5.1,
                                      ifelse(PctChange > 5, 5.1, PctChange))) %>%
  select(PctChange) %>%
  as.matrix() %>%
  as.vector() %>% 
  hist(x = ., breaks = (-11:11)/2, main = NA, xaxt = "n", xlab = "Daily Percent Change",
       col = c(colorRampPalette(c("red4", "red"), 0.5)(11), colorRampPalette(c("green", "green4"))(11)))
axis(1, at = (-11:11)/2, labels = labelvec)
box()

```

\newpage

# Predictive Analysis: S&P 500

## Logistic Regression

We begin our analyses on the S&P 500 data by using a logistic model to predict increases or decreases in the S&P 500, starting with the weekly data before proceeding to the daily data. We first consider a model such that `Direction` is the response and `BVolume`, `Prev5GM`, `Prev5Pct`, and`Lag1` through `Lag5` are predictors, and fitting this model to the training data.

``` {r, echo = TRUE, eval = FALSE}

glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + BVolume + Prev5GM + Prev5Pct,
    data = SPWeeklyTrain, family = binomial)

```

This model contains the maximum number (8) of non-interactive predictors and is only one of many models that we can make; we could fit a model with only seven of these eight terms, six of these eight terms, five of these eight terms, and so on. As a matter of fact, one can prove that the total number of non-interactive models that we can form is \begin{equation} n=\sum_{i=1}^{8}\frac{8!}{i!(8-i)!}=255 \end{equation} which is computationally feasible if we wish to evaluate every single one of these possible models. However, fitting these models individually like we did in the code above would be too time consuming, so we write a function `logreg.comb` to do it for us.

``` {r echo = TRUE, eval = FALSE}

logreg.comb <- function(dataTrain, output, n){
  combn(names(dataTrain)[-c(2:3)], n) %>% 
    apply(FUN = paste0, MARGIN = 2, collapse = "+") %>% 
    paste0("Direction~", .) %>% 
    sapply(FUN = logreg, dataTrain = dataTrain, output = output) %>% 
    sort() %>%
    return()}

```

Here, we use the `combn` function to generate all 255 different combination of variables and then `paste0` to collapse them down into their individual formulas. We then use `sapply` to apply a custom function `logreg` to each of these formulas; this custom function fits a logistic regression using a given formula and training data set and returns a specified statistic such as accuracy, sensitivity, specificity, positive predictive value, or negative predictive value. Because this function is too long to properly include in a code snippet, we have not included it here and can instead be found in the markdown for this analysis.

After creating the functions `logreg` and  `logreg.comb`, we then use them to evaluate all 255 possible non-interactive models and find the one that maximises training set accuracy. Doing so yields the model \begin{equation} logit(\pi)=\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+\beta_{3}x_{3}+\beta_{4}x_{4}+\beta_{5}x_{5} \end{equation} with the predictor variables `BVolume` `Prev5GM`, `Lag2`, `Lag3`, and `Lag5`, and response $\pi$ representing the probability of an increase in value. We will call this model **Model 1**. This model has an accuracy of approximately 57.69% on the training data which, while low, still seems to be slightly better than guessing. However, we see that this accuracy is highly skewed towards predicting increases; our model has a training sensitivity of 91.72% and correctly classified 665 out of 725 increases, but has an extremely low specificity of 14.78% and correctly classified only 85 out of 575 decreases. Sensitivity and specificity may not be useful in the context of this problem, though; recall that they would interpreted such that given an increase (or decrease), the sensitivity (or specificity) is the probability of correctly identifying that increase (or decrease). However, if we are trying to predict the behaviour of a stock or ETF next week, then we are not given an increase or decrease then since that is what we are trying to predict in the first place! As such, it might make more sense to examine something like positive predictive value (PPV); that is, when the model predicts an increase, the percentage of times that an increase actually occurs. If we use `logreg.comb` again, but this time seeking to maximise the training PPV, we actually get the same model, with a PPV of 57.58% on the training data. We will call this model **Model 2** to distinguish it from Model 1 because though they are the same model, they were selected using different criteria. We can also try and maximise negative predictive value (NPV); that is, when the model predicts a decrease, the percentage of times that a decrease actually occurs. Upon doing so, we get the model \begin{equation} logit(\pi)=\beta_{0}+\beta_{1}x_{1} \end{equation} with `Prev5GM` as the only predictor. This model has an NPV of 100%, meaning that every time a decrease is predicted, the markets actually decrease. This number is suspiciously high, and after checking the confusion matrix, it is clear why: the model only predicted a decrease once and got it right, while the other 542 decreases were incorrectly predicted as increases. Even looking at the next few highest models in terms of NPV, we see the same trend of high NPVs due to a extremely low number of decreases that just so happened to be correctly predicted. As such, it might be wise to stick with accuracy and PPV when choosing our models.

We can also examine the training accuracy of models that include two-way interactions, as these interactions may help capture patterns in the data that our original non-interactive models might have missed. The total number of two-way interaction terms plus single terms is 36, so thus the total number of interactive models that we can form is \begin{equation} n=\sum_{i=1}^{36}\frac{36!}{i!(36-i)!}=68719476735. \end{equation} which is much larger than the number of possible models considering only non-interactive terms. Evaluating every single one of these possible models would be far too computationally expensive for R, and we thus cannot calculate the accuracy of each model like we did when we only had 255 models. However, we can develop a heuristic solution that only searches through several of these possible models rather than attempting to test them all; here, we create an algorithm that performs a backward search much like how the function `step` with argument `direction = "backward"` does, though selecting our models based on training data accuracy rather than Akaike's information criterion (AIC).

``` {r eval = FALSE, echo = TRUE}

# Function to remove a term and find new accuracy
logreg.lcv1 <- function(i, dataTrain, output){
  predVec[-i] %>% 
    paste0(., collapse = "+") %>% 
    paste0("Direction~", .) %>% 
    logreg(dataTrain = SPWeeklyTrain, output = output) %>% 
    return()}

# Function to return accuracy and new list of predictors after removing a predictor
logreg.bwd <- function(predVec, output){
  accs <- sapply(1:length(predVec), FUN = logreg.lcv1, dataTrain = SPWeeklyTrain,
                 output = output)
  pv <- predVec[-which.max(accs)]
  return(list(predVec = pv, maxacc = max(accs)))}

```

Here, we start with the maximum number (36) of interactive and non-interactive terms, and use an `output` of `accuracy` to select our models based on overall prediction accuracy. We then calculate the new training accuracy after we remove a term, and do this for each term, then removing the term that results in the highest accuracy. We repeat this process until the model accuracy is maximised. Doing so results in a model with a training accuracy of 59.77% and 32 terms; we will call this model **Model 3**. Model 3 has the structure \begin{equation} logit(\pi)=\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+...+\beta_{32}x_{32} \end{equation} and has so many terms that it would not be practical to list them here. We can also perform forward selection, starting with a null model and calculating the new training accuracy after adding a term, doing this for each term, and then adding the term that results in the highest accuracy.

``` {r eval = FALSE, echo = TRUE}

# Function to add a term and find new accuracy
logreg.lcv2 <- function(i, dataTrain, output){
  c(predVecFwd, predVecRemain[i]) %>% 
  paste0(., collapse = "+") %>% 
    paste0("Direction~", .) %>% 
    logreg(dataTrain = SPWeeklyTrain, output = output) %>% 
    return()}

# Function to return accuracy and new list of predictors after adding a predictor
logreg.fwd <- function(predVecRemain, predVecFwd, output){
  accs <- sapply(1:length(predVecRemain), FUN = logreg.lcv2, dataTrain = SPWeeklyTrain,
                 output = output)
  pvf <- c(predVecFwd, predVecRemain[which.max(accs)])
  pvr <- predVecRemain[-which.max(accs)]
  return(list(predVecFwd = pvf, predVecRemain = pvr, maxacc = max(accs)))}

```

Doing so now results in a model with a training accuracy of 57.15% and 7 terms; we will call this model **Model 4**. While the training accuracy is lower on this model, there are fewer terms than our Model 3 resulting from backward selection. We can also use the same forward and backward algorithms but select models using PPV instead of accuracy. If we do so using the backward step algorithm, we get a model with a PPV of 59.24% and 32 terms; we will call this model **Model 5**. While this model has the same number of terms as Model 3, the terms and coefficient estimates are not identical. Using the forward step algorithm, we get a model with a PPV of 57.71% and 10 terms; we will call this model **Model 6**.

Now that we have three models (1, 3, and 4) selected by maximising overall accuracy and three models (2, 5, and 6) selected by maximising PPv, we can compare their performance. Model 3 has the highest overall accuracy on the training data at 59.77% and, interestingly, also has the highest PPV at 59.32%; the fact that this model has a higher PPV than any of the models that were explicitly selected by maximising PPv suggests that the heuristic algorithm used in Model 5 and Model 6 may have only found a local maximum rather than a global maximum. We can also plot an ROC curve for each model, as has been done in Figures \ref{fig:Figure19} and \ref{fig:Figure20}; here, we see that Model 3 has the second-highest area under the curve (AUC) at 0.5893. Model 5 has the highest AUC at 0.5900, though only by a slight margin, and has only a slightly lower accuracy (59.62%) and PPV (59.24%) than Model 3, making these two models extremely competitive.

However, we also need to assess model performance on the test data. We again see that model 3 has the highest accuracy (64.38%) and highest PPV (64.18%), and this time even has a higher AUC (0.6538) than Model 5. Model 5 is still a close second, though, with an accuracy of 64.00%, PPV of 63.96%, and AUC of 0.6428.

We can also check the residuals for these models to ensure that the logistic model is an appropriate fit. As can be seen in Figures \ref{fig:Figure21} and \ref{fig:Figure22}, most of the residuals are resemble those of a typical logistic regression: two bands above and below zero, with a loess fit that approximates a horizontal line at zero. However, significant curvature of the loess fit to the residuals of Model 4 and Model 6 suggest that the logistic model may not be satisfactory in these instances.

So far, we see that Model 3 and Model 5 have overall accuracies and PPVs close to 60%, which is surprisingly high considering the lack of autocorrelation in our data and how noisy stock market data can be. But how can we connect model accuracy and PPV back to return on investment? While accuracy and PPV are excellent ways to understand the predictive capabilities of our models, we also seek to understand whether or not these models can "beat the market", so to speak.

We can do this by applying the models to the test data, and using model predictions to calculate the cumulative percent change at each point in time, as has been done in the left panels of Figures \ref{fig:Figure23} and \ref{fig:Figure24}. The black lines represent a buy-and-hold strategy without any action informaed from the model; that is, an investor would simply buy shares and hold them without selling, regardless of the increases and decreases in value along the way. We see that under a buy-and-hold strategy, an investor that purchased shares at the beginning of 2011 would find that their investment would be worth approximately 2.30 times as much at the beginning of 2021, which represents an approximately 130% increase in value over the course of a decade. The blue lines represent the strategy of selling all shares before a predicted decrease, then buying them back before the next predicted increase, effectively sheltering all assets from a suspected dip. This stategy works extremely well for Model 3 and Model 5, with investments respectively reaching 6.95 and 6.57 times their initial value. However, liquidating all assets only to buy them back is extremely risky, so one could also employ a strategy of selling only 35% of assets before a predicted decrease and then buying them back at the next predicted increase; this strategy is represented by the purple lines. Even with this less risky strategy, investments under the guidance of Model 3 and Model 5 reach 3.44 and 3.37 times their initial value, which still yields a higher return on investment than a buy-and-hold strategy.

The other four models, however, do not perform as well as Model 3 and Model 5. Even with the risky strategy represented by the blue lines in Figures \ref{fig:Figure23} and \ref{fig:Figure24}, the next best models (Model 1 and 2 which, recall, are identical) see the initial investment reach 2.88 times its initial value, which while still better than the buy-and-hold strategy, are nowhere close the gains that Model 3 and Model 5 yield. Furthermore, these increases over the buy-and-hold strategy only happen in the small window from 2020-2021, after the beginning of the dip caused by the COVID-19 pandemic; before this, performance is almost identical to that of the buy-and-hold strategy.

So then, how can Model 3 and Model 5 differ so drastically from the other four models when it comes to return on investment? After all, the largest difference in model accuracy is only 4.19% and only 3.37% when it comes to PPV, so how can such small differences be amplified? Part of the reason lies within the number and timing of predicted increases and decreases, which can be seen in the right panels in Figures \ref{fig:Figure23} and \ref{fig:Figure24}. These panels show what happens on the weeks that the model predicted a decrease; on these weeks, investors using the blue line strategy would not be exposed to any increase or decrease in value, and investors using the less risky purple line strategy would only be exposed to 35% of each increase or decrease in value. We see that the magnitude of the mean percent decrease during these weeks is approximately equal to the magnitude of the mean percent increase, so it's not like decreases tend to be stronger or weaker than increases on weeks where a decrease is predicted. However, we do see that Model 3 and Model 5 have a high ratio of decreases avoided to increases avoided; Model 3 avoided 46 decreases and only 24 increases, while Model 5 avoided 45 decreases and only 25 increases. Compare this to the other four models, where the number of decreases avoided is only slightly greater than or approximately equal to the number of increases avoided and we can see that by avoiding significantly more decreases than increases, Model 3 and Model 5 shield investors from decreases while sacrificing only a relatively small number of increases. We also see differences in the timing of these decreases avoided; while Model 3 and Model 5 have the decreases avoided more evenly distributed through time, the other four models tend to have their decreases avoided concentrated in 2020 and 2021. When decreases are avoided earlier in the investment period, the investment increases in value relative to the buy-and-hold strategy, and this investment has a longer time to experience multiplicative increases in value than if decreases are avoided closer to the end of the investment period. Thus, because Model 3 and Model 5 avoid more decreases and do so more consistently throughout the investment period compared to the other four models, the investment value increases faster and more often relative to the other four models or the buy-and-hold strategy.

``` {r include = FALSE}

# Note: Our analyses show that VLag1 - VLag5 doesn't make much of a difference
# Thus, we remove it to make the models simpler
select(SPWeeklyTrain, !(VLag1:VLag5)) -> SPWeeklyTrain
select(SPWeeklyTest, !(VLag1:VLag5)) -> SPWeeklyTest

# Function to perform logistic regression and output predictive accuracy
logreg <- function(formula, dataTrain, output){
  
  # Fit logistic regression using training data
  glm.fit <- glm(formula, data = dataTrain, family = "binomial")
  
  # Classify training data; get posterior probabilities
  glm.probs <- predict(glm.fit, dataTrain, type = "response")
  glm.pred <- rep("Down", length(glm.probs))
  glm.pred[glm.probs >= 0.5] <- "Up"
  
  # Confusion matrix of classified observations
  # Must manually add Down row if model never predicts Down
  confMatrix <- table(glm.pred, dataTrain$Direction)
  if(nrow(confMatrix) == 1){
    confMatrix <- rbind(c(0, 0), confMatrix)}
  rownames(confMatrix) <- c("[P]Down", "[P]Up")
  colnames(confMatrix) <- c("[O]Down", "[O]Up")
  
  # Overall predictive accuracy
  accuracy <- sum(diag(confMatrix)/sum(confMatrix))
  
  # Sensitivity and specificity
  specificity <- confMatrix[1, 1]/sum(confMatrix[, 1])
  sensitivity <- confMatrix[2, 2]/sum(confMatrix[, 2])
  
  # Positive and negative predictive value
  npv <- confMatrix[1, 1]/sum(confMatrix[1, ])
  ppv <- confMatrix[2, 2]/sum(confMatrix[2, ])
  
  # Return individual outputs or list of all outputs
  if(output == "all"){
    return(list(confMatrix = confMatrix, accuracy = accuracy, specificity = specificity,
              sensitivity = sensitivity, npv = npv, ppv = ppv))}
  if(output == "confMatrix"){
    return(confMatrix)}
  if(output == "accuracy"){
    return(accuracy)}
  if(output == "specificity"){
    return(specificity)}
  if(output == "sensitivity"){
    return(sensitivity)}
  if(output == "npv"){
    return(npv)}
  if(output == "ppv"){
    return(ppv)}}

```

``` {r include = FALSE}

# Function to fit logistic regression to all possible combinations of n variables
# Outputs value and combination of variables for desired prediction metric
logreg.comb <- function(dataTrain, output, n){
  combn(names(dataTrain)[-c(2:3)], n) %>% 
    apply(FUN = paste0, MARGIN = 2, collapse = "+") %>% 
    paste0("Direction~", .) %>% 
    sapply(FUN = logreg, dataTrain = dataTrain, output = output) %>% 
    sort() %>%
    return()}

# Create empty list to populate with top models
SPWeeklyLMod <- list()

# Find top 10 models for accuracy
SPWeeklyTop <- unlist(sapply(1:8, FUN = logreg.comb, dataTrain = SPWeeklyTrain, output = "accuracy"))
sort(SPWeeklyTop, decreasing = TRUE)[1:10]
SPWeeklyLMod[[1]] <- names(sort(SPWeeklyTop, decreasing = TRUE)[1])
logreg(SPWeeklyLMod[[1]], dataTrain = SPWeeklyTrain, output = "confMatrix")

# Find top 10 models for ppv
SPWeeklyTop <- unlist(sapply(1:8, FUN = logreg.comb, dataTrain = SPWeeklyTrain, output = "ppv"))
sort(SPWeeklyTop, decreasing = TRUE)[1:10]
SPWeeklyLMod[[2]] <- names(sort(SPWeeklyTop, decreasing = TRUE)[1])
logreg(SPWeeklyLMod[[2]], dataTrain = SPWeeklyTrain, output = "confMatrix")

# Find top 10 models for npv
SPWeeklyTop <- unlist(sapply(1:8, FUN = logreg.comb, dataTrain = SPWeeklyTrain, output = "npv"))
sort(SPWeeklyTop, decreasing = TRUE)[1:10]
logreg(names(sort(SPWeeklyTop, decreasing = TRUE))[1], dataTrain = SPWeeklyTrain, output = "confMatrix")

# Remove variables from global environment
remove(SPWeeklyTop)

```

``` {r include = FALSE}

# Function to remove a term and find new accuracy
logreg.lcv1 <- function(i, dataTrain, output){
  predVec[-i] %>% 
    paste0(., collapse = "+") %>% 
    paste0("Direction~", .) %>% 
    logreg(dataTrain = SPWeeklyTrain, output = output) %>% 
    return()}

# Function to return accuracy and new list of predictors after removing a predictor
logreg.bwd <- function(predVec, output){
  accs <- sapply(1:length(predVec), FUN = logreg.lcv1, dataTrain = SPWeeklyTrain, output = output)
  pv <- predVec[-which.max(accs)]
  return(list(predVec = pv, maxacc = max(accs)))}

# Function to add a term and find new accuracy
logreg.lcv2 <- function(i, dataTrain, output){
  c(predVecFwd, predVecRemain[i]) %>% 
  paste0(., collapse = "+") %>% 
    paste0("Direction~", .) %>% 
    logreg(dataTrain = SPWeeklyTrain, output = output) %>% 
    return()}

# Function to return accuracy and new list of predictors after adding a predictor
logreg.fwd <- function(predVecRemain, predVecFwd, output){
  accs <- sapply(1:length(predVecRemain), FUN = logreg.lcv2, dataTrain = SPWeeklyTrain, output = output)
  pvf <- c(predVecFwd, predVecRemain[which.max(accs)])
  pvr <- predVecRemain[-which.max(accs)]
  return(list(predVecFwd = pvf, predVecRemain = pvr, maxacc = max(accs)))}

# Apply backward step algorithm using accuracy
combn(names(SPWeeklyTrain)[-c(2:3)], 2) %>%
    apply(FUN = paste0, MARGIN = 2, collapse = ":") %>%
    c(names(SPWeeklyTrain)[-c(2:3)]) -> predVec
prevmaxacc <- c(0.5, 0.5)
maxacc <- logreg.bwd(predVec, "accuracy")$maxacc
predVec <- logreg.bwd(predVec, "accuracy")$predVec
prevmaxacc <- c(prevmaxacc, maxacc)
while(length(predVec) > 1){
  maxacc <- logreg.bwd(predVec, "accuracy")$maxacc
  if(maxacc < prevmaxacc[length(prevmaxacc) - 1]){
    break}
  predVec <- logreg.bwd(predVec, "accuracy")$predVec
  prevmaxacc <- c(prevmaxacc, maxacc)}
prevmaxacc[length(prevmaxacc)]
SPWeeklyLMod[[3]] <- paste0("Direction~", paste0(predVec, collapse = "+"))

# Apply forward step algorithm using accuracy
combn(names(SPWeeklyTrain)[-c(2:3)], 2) %>%
    apply(FUN = paste0, MARGIN = 2, collapse = ":") %>%
    c(names(SPWeeklyTrain)[-c(2:3)]) -> predVecRemain
prevmaxacc <- c(0.5, 0.5)
predVecFwd <- c()
maxacc <- logreg.fwd(predVecRemain, predVecFwd, "accuracy")$maxacc
predVecFwd <- logreg.fwd(predVecRemain, predVecFwd, "accuracy")$predVecFwd
predVecRemain <- predVecRemain[predVecRemain != predVecFwd[length(predVecFwd)]]
prevmaxacc <- c(prevmaxacc, maxacc)
while(length(predVecFwd) < 36){
  maxacc <- logreg.fwd(predVecRemain, predVecFwd, "accuracy")$maxacc
  if(maxacc < prevmaxacc[length(prevmaxacc) - 1]){
    break}
  predVecFwd <- logreg.fwd(predVecRemain, predVecFwd, "accuracy")$predVecFwd
  predVecRemain <- predVecRemain[predVecRemain != predVecFwd[length(predVecFwd)]]
  prevmaxacc <- c(prevmaxacc, maxacc)}
prevmaxacc[length(prevmaxacc)]
SPWeeklyLMod[[4]] <- paste0("Direction~", paste0(predVecFwd, collapse = "+"))

# Apply backward step algorithm using PPV
combn(names(SPWeeklyTrain)[-c(2:3)], 2) %>%
    apply(FUN = paste0, MARGIN = 2, collapse = ":") %>%
    c(names(SPWeeklyTrain)[-c(2:3)]) -> predVec
prevmaxacc <- c(0.5, 0.5)
maxacc <- logreg.bwd(predVec, "ppv")$maxacc
predVec <- logreg.bwd(predVec, "ppv")$predVec
prevmaxacc <- c(prevmaxacc, maxacc)
while(length(predVec) > 1){
  maxacc <- logreg.bwd(predVec, "ppv")$maxacc
  if(maxacc < prevmaxacc[length(prevmaxacc) - 1]){
    break}
  predVec <- logreg.bwd(predVec, "ppv")$predVec
  prevmaxacc <- c(prevmaxacc, maxacc)}
prevmaxacc[length(prevmaxacc)]
SPWeeklyLMod[[5]] <- paste0("Direction~", paste0(predVec, collapse = "+"))

# Apply forward step algorithm using PPV
combn(names(SPWeeklyTrain)[-c(2:3)], 2) %>%
    apply(FUN = paste0, MARGIN = 2, collapse = ":") %>%
    c(names(SPWeeklyTrain)[-c(2:3)]) -> predVecRemain
prevmaxacc <- c(0.5, 0.5)
predVecFwd <- c()
maxacc <- logreg.fwd(predVecRemain, predVecFwd, "ppv")$maxacc
predVecFwd <- logreg.fwd(predVecRemain, predVecFwd, "ppv")$predVecFwd
predVecRemain <- predVecRemain[predVecRemain != predVecFwd[length(predVecFwd)]]
prevmaxacc <- c(prevmaxacc, maxacc)
while(length(predVecFwd) < 36){
  maxacc <- logreg.fwd(predVecRemain, predVecFwd, "ppv")$maxacc
  if(maxacc < prevmaxacc[length(prevmaxacc) - 1]){
    break}
  predVecFwd <- logreg.fwd(predVecRemain, predVecFwd, "ppv")$predVecFwd
  predVecRemain <- predVecRemain[predVecRemain != predVecFwd[length(predVecFwd)]]
  prevmaxacc <- c(prevmaxacc, maxacc)}
prevmaxacc[length(prevmaxacc)]
SPWeeklyLMod[[6]] <- paste0("Direction~", paste0(predVecFwd, collapse = "+"))

# Remove variables from global environment
remove(maxacc, predVec, predVecFwd, predVecRemain, prevmaxacc)

```

``` {r include = FALSE}

# Compare model test accuracy
sapply(SPWeeklyLMod, FUN = logreg, dataTrain = SPWeeklyTest, output = "accuracy")

# Compare model test PPV
sapply(SPWeeklyLMod, FUN = logreg, dataTrain = SPWeeklyTest, output = "ppv")

# Function to estimate total return on model vs no model
# Assumes complete liquidation of assets prior to predicted decrease
# Setting lrisk to TRUE liquidates only 35% of assets prior to predicted decrease
returns.logreg <- function(formula, data, final = FALSE, lrisk = FALSE){
  if(formula != "none"){
    glm.fit <- glm(formula = formula, data = data, family = "binomial")
    glm.probs <- predict(glm.fit, data, type = "response")
    glm.pred <- rep("Down", length(glm.probs))
    glm.pred[glm.probs >= 0.5] <- "Up"
    pcts <- data$PctChange
    if(lrisk == FALSE){
      pcts[glm.pred == "Down"] <- 0}
    if(lrisk == TRUE){
      pcts[glm.pred == "Down"] <- pcts[glm.pred == "Down"]*0.65}
    totalReturn <- c()
    for(i in 1:length(pcts)){
      totalReturn <- c(totalReturn, prod((pcts[1:i]/100)+1))}}
  if(formula == "none"){
    totalReturn <- c()
    for(i in 1:nrow(data)){
      totalReturn <- c(totalReturn, prod((data$PctChange[1:i]/100)+1))}}
  ifelse(final == TRUE, return(totalReturn[length(totalReturn)]), return(totalReturn))}

# Compare lifetime returns; use loop since sapply doesn't work for some reason
for(i in 1:6){
  print(returns.logreg(SPWeeklyLMod[[i]], data = SPWeeklyTest, final = TRUE))}

```

``` {r eval = FALSE}

# Code above can be modified to get top 10 models for sensitivity, specificity, and NPV
# Not particularly useful, so they won't be used much in our analyses

# Get statistics from top 10 models in terms of accuracy
SPWeeklyTopA <- lapply(names(sort(SPWeeklyTop, decreasing = TRUE)[1:10]),
                       FUN = glm, data = SPWeeklyTrain, family = "binomial")

# Get coefficients from top 10 models
lapply(SPWeeklyTopA, FUN = coef) %>% 
  lapply(FUN = as.list) -> coeflist

# Create table of coefficients, AIC, and accuracy
SPWeeklyTopATab <- cbind(do.call(rbind.fill, lapply(coeflist, as.data.frame)),
                         sapply(SPWeeklyTopA, FUN = AIC),
                         as.numeric(sort(SPWeeklyTop, decreasing = TRUE)[1:10]))
names(SPWeeklyTopATab)[c(1, 9, 10, 11)] <- c("Intercept", "Lag1", "AIC", "Accuracy")

# Calculate maximum VIF for each model
sapply(sapply(SPWeeklyTopA, FUN = vif), FUN = max)

# Reorder table columns
SPWeeklyTopATab <- SPWeeklyTopATab[, c(1, 9, 2:4, 8, 5:7, 10:11)]

# Find top 10 models for PPV
SPWeeklyTop <- unlist(sapply(1:8, FUN = logreg.comb, dataTrain = SPWeeklyTrain,
                      dataTest = SPWeeklyTest, output = "ppv"))
sort(SPWeeklyTop, decreasing = TRUE)[1:10]

# Get statistics from top 10 models in terms of PPV
SPWeeklyTopP <- lapply(names(sort(SPWeeklyTop, decreasing = TRUE)[1:10]),
                       FUN = glm, data = SPWeeklyTrain, family = "binomial")

# Get coefficients from top 10 models
lapply(SPWeeklyTopP, FUN = coef) %>% 
  lapply(FUN = as.list) -> coeflist

# Create table of coefficients, AIC, max VIF, and accuracy
SPWeeklyTopPTab <- cbind(do.call(rbind.fill, lapply(coeflist, as.data.frame)),
                         sapply(SPWeeklyTopP, FUN = AIC),
                         as.numeric(sort(SPWeeklyTop, decreasing = TRUE)[1:10]))
names(SPWeeklyTopPTab)[c(1, 10, 11)] <- c("Intercept", "AIC", "PPV")

# Calculate maximum VIF for each model
sapply(sapply(SPWeeklyTopP, FUN = vif), FUN = max)

# Reorder table columns
SPWeeklyTopPTab <- SPWeeklyTopPTab[, c(1, 8, 2:3, 6:7, 9, 4, 5, 10:11)]

# Remove unneeded variables
remove(SPWeeklyTop, coeflist)

# Direction ~ Lag2 + Lag3 + Prev5Pct + Volume seems like the best candidate
# 2nd highest accuracy and highest PPV

```

``` {r eval = FALSE}

# Print tables of top 10 logistic models for accuracy and PPV
options(knitr.kable.NA = '')
kable(round(SPWeeklyTopATab, 3))
kable(round(SPWeeklyTopPTab, 3))

```

``` {r Figure19, fig.height = 8.3, warning = FALSE, message = FALSE, fig.cap = "\\label{fig:Figure19} ROC curves for the logistic regression models selected by maximising accuracy. Accuracy, positive predictive value (PPV), and area under the curve (AUC) are listed for each plot; the red dot represents model sensitivity and specificity."}

par(mfrow = c(3, 2))

for(i in c(1, 3, 4)){
  
  if(i == 1){j <- 1}
  if(i == 3){j <- 2}
  if(i == 4){j <- 3}
  
  glm.stats <- sapply(c("accuracy", "sensitivity", "specificity", "ppv"),
                      FUN = logreg, formula = SPWeeklyLMod[[i]], dataTrain = SPWeeklyTrain)
  glm.fit <- glm(SPWeeklyLMod[[i]], data = SPWeeklyTrain, family = "binomial")
  glm.probs <- predict(glm.fit, SPWeeklyTrain, type = "response")
  auc <- roc(SPWeeklyTrain$Direction, glm.probs, direction = "<")$auc
  roc(SPWeeklyTrain$Direction, glm.probs, plot = TRUE, direction = "<", mar = c(4, 4, 1, 2) + 0.1)
  text(x = rep(1.1, 3)[j], y = rep(0.98, 3)[j],
       labels = c("Model 1: Train", "Model 3: Train", "Model 4: Train")[j], adj = 0)
  text(x = rep(1.1, 3), y = c(0.9, 0.83, 0.76), labels = c("Acc:", "PPV:", "AUC:"), adj = 0)
  text(x = rep(0.94, 3), y = c(0.9, 0.83, 0.76), labels = round(as.numeric(c(glm.stats[c(1, 4)], auc)), 4), adj = 0)
  points(x = glm.stats[3], y = glm.stats[2], col = "red", pch = 16)
  
  glm.stats <- sapply(c("accuracy", "sensitivity", "specificity", "ppv"),
                      FUN = logreg, formula = SPWeeklyLMod[[i]], dataTrain = SPWeeklyTest)
  glm.fit <- glm(SPWeeklyLMod[[i]], data = SPWeeklyTest, family = "binomial")
  glm.probs <- predict(glm.fit, SPWeeklyTest, type = "response")
  auc <- roc(SPWeeklyTest$Direction, glm.probs, direction = "<")$auc
  roc(SPWeeklyTest$Direction, glm.probs, plot = TRUE, direction = "<", mar = c(4, 4, 1, 2) + 0.1)
  text(x = rep(1.1, 3)[j], y = rep(0.98, 3)[j],
       labels = c("Model 1: Test", "Model 3: Test", "Model 4: Test")[j], adj = 0)
  text(x = rep(1.1, 3), y = c(0.9, 0.83, 0.76), labels = c("Acc:", "PPV:", "AUC:"), adj = 0)
  text(x = rep(0.94, 3), y = c(0.9, 0.83, 0.76), labels = round(as.numeric(c(glm.stats[c(1, 4)], auc)), 4), adj = 0)
  points(x = glm.stats[3], y = glm.stats[2], col = "red", pch = 16)}

```

``` {r Figure20, fig.height = 8.3, warning = FALSE, message = FALSE, fig.cap = "\\label{fig:Figure20} ROC curves for the logistic regression models selected by maximising PPV. Accuracy, positive predictive value (PPV), and area under the curve (AUC) are listed for each plot; the red dot represents model sensitivity and specificity."}

par(mfrow = c(3, 2))

for(i in c(2, 5, 6)){
  
  if(i == 2){j <- 1}
  if(i == 5){j <- 2}
  if(i == 6){j <- 3}
  
  glm.stats <- sapply(c("accuracy", "sensitivity", "specificity", "ppv"),
                      FUN = logreg, formula = SPWeeklyLMod[[i]], dataTrain = SPWeeklyTrain)
  glm.fit <- glm(SPWeeklyLMod[[i]], data = SPWeeklyTrain, family = "binomial")
  glm.probs <- predict(glm.fit, SPWeeklyTrain, type = "response")
  auc <- roc(SPWeeklyTrain$Direction, glm.probs, direction = "<")$auc
  roc(SPWeeklyTrain$Direction, glm.probs, plot = TRUE, direction = "<", mar = c(4, 4, 1, 2) + 0.1)
  text(x = rep(1.1, 3)[j], y = rep(0.98, 3)[j],
       labels = c("Model 2: Train", "Model 5: Train", "Model 6: Train")[j], adj = 0)
  text(x = rep(1.1, 3), y = c(0.9, 0.83, 0.76), labels = c("Acc:", "PPV:", "AUC:"), adj = 0)
  text(x = rep(0.94, 3), y = c(0.9, 0.83, 0.76), labels = round(as.numeric(c(glm.stats[c(1, 4)], auc)), 4), adj = 0)
  points(x = glm.stats[3], y = glm.stats[2], col = "red", pch = 16)
  
  glm.stats <- sapply(c("accuracy", "sensitivity", "specificity", "ppv"),
                      FUN = logreg, formula = SPWeeklyLMod[[i]], dataTrain = SPWeeklyTest)
  glm.fit <- glm(SPWeeklyLMod[[i]], data = SPWeeklyTest, family = "binomial")
  glm.probs <- predict(glm.fit, SPWeeklyTest, type = "response")
  auc <- roc(SPWeeklyTest$Direction, glm.probs, direction = "<")$auc
  roc(SPWeeklyTest$Direction, glm.probs, plot = TRUE, direction = "<", mar = c(4, 4, 1, 2) + 0.1)
  text(x = rep(1.1, 3)[j], y = rep(0.98, 3)[j],
       labels = c("Model 2: Test", "Model 5: Test", "Model 6: Test")[j], adj = 0)
  text(x = rep(1.1, 3), y = c(0.9, 0.83, 0.76), labels = c("Acc:", "PPV:", "AUC:"), adj = 0)
  text(x = rep(0.94, 3), y = c(0.9, 0.83, 0.76), labels = round(as.numeric(c(glm.stats[c(1, 4)], auc)), 4), adj = 0)
  points(x = glm.stats[3], y = glm.stats[2], col = "red", pch = 16)}

```

``` {r Figure21, fig.height = 8, warning = FALSE, fig.cap = "\\label{fig:Figure21} Standardised deviance residuals (left) and standardised Pearson residuals (right) for logistic regression models selected using accuracy. Solid red lines represent a loess fit to the residuals and should be approximately horizontal at zero; dotted red lines represent $\\pm$ 2 standard deviations on the residuals."}

# Re-fit top models to get residuals
SPWeeklyLModList <- lapply(SPWeeklyLMod, FUN = glm, data = SPWeeklyTrain, family = "binomial")

# Generate residual plots
par(mfrow = c(3, 2), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
for(i in c(1, 3, 4)){
  
  # Offset numbers for indexing purposes
  if(i == 1){j <- 1}
  if(i == 3){j <- 2}
  if(i == 4){j <- 3}
  
  # Calculate leverage and residuals
  hvals <- influence(SPWeeklyLModList[[i]])$hat
  SRDeviance <- rstandard(SPWeeklyLModList[[i]])
  SRPearson <- residuals(SPWeeklyLModList[[i]], "pearson")/sqrt(1 - hvals)
  
  # Plot standardised deviance residuals
  plot(predict(SPWeeklyLModList[[i]], type = "response"), SRDeviance, xlab = "Fitted Probability",
       col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylim = c(-3, 3),
       ylab = "Standardised Deviance Residuals", xlim = if(i == 4){c(0.3, 0.8)})
  lines(lowess(predict(SPWeeklyLModList[[i]]), residuals(SPWeeklyLModList[[i]])), col = "red", lwd = 1.5)
  abline(h = c(-2, 2), col = "red", lty = 3, lwd = 1.5)
  text(x = c(0.294, 0.021, 0.29)[j], y = rep(2.85, 3)[j], labels = c("Model 1", "Model 3", "Model 4")[j], adj = 0)

  # Plot standardised Pearson residuals
  plot(predict(SPWeeklyLModList[[i]], type = "response"), SRPearson, xlab = "Fitted Probability",
       col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylim = c(-3, 3),
       ylab = "Pearson Deviance Residuals", xlim = if(i == 4){c(0.3, 0.8)})
  lines(lowess(predict(SPWeeklyLModList[[i]]), residuals(SPWeeklyLModList[[i]], "pearson")), col = "red", lwd = 1.5)
  abline(h = c(-2, 2), col = "red", lty = 3, lwd = 1.5)
  text(x = c(0.294, 0.021, 0.29)[j], y = rep(2.85, 3)[j], labels = c("Model 1", "Model 3", "Model 4")[j], adj = 0)}

```

``` {r Figure22, fig.height = 8, warning = FALSE, fig.cap = "\\label{fig:Figure22} Standardised deviance residuals (left) and standardised Pearson residuals (right) for logistic regression models selected using PPV. Solid red lines represent a loess fit to the residuals and should be approximately horizontal at zero; dotted red lines represent $\\pm$ 2 standard deviations on the residuals."}

# Re-fit top models to get residuals
SPWeeklyLModList <- lapply(SPWeeklyLMod, FUN = glm, data = SPWeeklyTrain, family = "binomial")

# Generate residual plots
par(mfrow = c(3, 2), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
for(i in c(2, 5, 6)){
  
  # Offset numbers for indexing purposes
  if(i == 2){j <- 1}
  if(i == 5){j <- 2}
  if(i == 6){j <- 3}
  
  # Calculate leverage and residuals
  hvals <- influence(SPWeeklyLModList[[i]])$hat
  SRDeviance <- rstandard(SPWeeklyLModList[[i]])
  SRPearson <- residuals(SPWeeklyLModList[[i]], "pearson")/sqrt(1 - hvals)
  
  # Plot standardised deviance residuals
  plot(predict(SPWeeklyLModList[[i]], type = "response"), SRDeviance, xlab = "Fitted Probability",
       col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylim = c(-3, 3),
       ylab = "Standardised Deviance Residuals", xlim = if(i %in% c(2, 6)){
                                                            if(i == 2){c(0.3, 0.8)} else {c(0.2, 1)}})
  lines(lowess(predict(SPWeeklyLModList[[i]]), residuals(SPWeeklyLModList[[i]])), col = "red", lwd = 1.5)
  abline(h = c(-2, 2), col = "red", lty = 3, lwd = 1.5)
  text(x = c(0.293, 0.003, 0.19)[j], y = rep(2.85, 3)[j], labels = c("Model 2", "Model 5", "Model 6")[j], adj = 0)

  # Plot standardised Pearson residuals
  plot(predict(SPWeeklyLModList[[i]], type = "response"), SRPearson, xlab = "Fitted Probability",
       col = rgb(red = 0, green = 0, blue = 0, alpha = 0.3), pch = 16, ylim = c(-3, 3),
       ylab = "Pearson Deviance Residuals", xlim = if(i %in% c(2, 6)){
                                                       if(i == 2){c(0.3, 0.8)} else {c(0.2, 1)}})
  lines(lowess(predict(SPWeeklyLModList[[i]]), residuals(SPWeeklyLModList[[i]], "pearson")), col = "red", lwd = 1.5)
  abline(h = c(-2, 2), col = "red", lty = 3, lwd = 1.5)
  text(x = c(0.293, 0.003, 0.19)[j], y = rep(2.85, 3)[j], labels = c("Model 2", "Model 5", "Model 6")[j], adj = 0)}

```

``` {r Figure23, fig.height = 7.8, warning = FALSE, fig.cap = "\\label{fig:Figure23} Relative value of the S\\&P 500 from 2011-2021 (left) and percent change for weeks in 2011-2021 for which an increase was not predicted (right) based on logistic regression models fit to the 1986-2010 data; the three models here were selected using overall accuracy. The black line represents a buy-and-hold strategy, while the blue line represents a strategy of selling all assets before a predicted decrease and then purchasing them back the next time there is a predicted increase. The purple line represents a less risky strategy of only selling 35\\% of assets before a predicted decrease and then purchasing them back the next time there is a predicted increase."}

# Generate plots
par(mfrow = c(3, 2), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
for(i in c(1, 3, 4)){
  
  # Offset numbers for indexing purposes
  if(i == 1){j <- 1}
  if(i == 3){j <- 2}
  if(i == 4){j <- 3}
  
  # Plot returns
  plot(returns.logreg(SPWeeklyLMod[[i]], data = SPWeeklyTest), type = "l", col = "blue", xaxt = "n",
       xlab = "Year", ylab = "Proportion of Initial Value", ylim = c(0, 8))
  axis(1, at = nrow(SPWeeklyTest)*(0:5)/5, labels = seq(2011, 2021, length.out = 6), cex.axis = 0.85)
  lines(returns.logreg(SPWeeklyLMod[[i]], data = SPWeeklyTest, lrisk = TRUE), col = "purple")
  lines(returns.logreg("none", data = SPWeeklyTest))
  text(x = rep(-8, 3)[j], y = rep(7.8, 3)[j], labels = c("Model 1", "Model 3", "Model 4")[j], adj = 0)
  
  # Plot increases/decreases on weeks when mode predicts a decrease
  glm.fit <- glm(SPWeeklyLMod[[i]], data = SPWeeklyTest, family = "binomial")
  glm.probs <- predict(glm.fit, SPWeeklyTest, type = "response")
  glm.pred <- rep("Down", length(glm.probs))
  glm.pred[glm.probs >= 0.5] <- "Up"
  plotdat <- data.frame(glm.pred, SPWeeklyTest$Direction, SPWeeklyTest$PctChange)
  plotdat <- subset(plotdat, glm.pred == "Down")
  plot(as.numeric(rownames(plotdat)), plotdat$SPWeeklyTest.PctChange, pch = 16, xaxt = "n",
       xlim = c(0, nrow(SPWeeklyTest)), col = ifelse(plotdat$SPWeeklyTest.PctChange < 0, "red", "green"),
       xlab = "Year", ylab = "Weekly Percent Change", ylim = c(-16, 16), cex.axis = 0.9)
  axis(1, at = nrow(SPWeeklyTest)*(0:5)/5, labels = seq(2011, 2021, length.out = 6), cex.axis = 0.85)
  abline(h = mean(plotdat$SPWeeklyTest.PctChange[plotdat$SPWeeklyTest.PctChange < 0]), lty = 2, col = "red")
  abline(h = mean(plotdat$SPWeeklyTest.PctChange[plotdat$SPWeeklyTest.PctChange > 0]), lty = 2, col = "green")
  text(x = rep(-8, 3)[j], y = rep(15, 3)[j], labels = c("Model 1", "Model 3", "Model 4")[j], adj = 0)
  text(x = rep(110, 3)[j], y = rep(15, 3)[j], labels = as.numeric(table(plotdat$SPWeeklyTest.Direction)[1]),
       col = "red", adj = 0)
  text(x = rep(140, 3)[j], y = rep(15, 3)[j], labels = "/", adj = 0)
  text(x = rep(150, 3)[j], y = rep(15, 3)[j], labels = as.numeric(table(plotdat$SPWeeklyTest.Direction)[2]),
       col = "green", adj = 0)}

```

``` {r Figure24, fig.height = 7.8, warning = FALSE, fig.cap = "\\label{fig:Figure24} Relative value of the S\\&P 500 from 2011-2021 (left) and percent change for weeks in 2011-2021 for which an increase was not predicted (right) based on logistic regression models fit to the 1986-2010 data; the three models here were selected using PPV. The black line represents a buy-and-hold strategy, while the blue line represents a strategy of selling all assets before a predicted decrease and then purchasing them back the next time there is a predicted increase. The purple line represents a less risky strategy of only selling 35\\% of assets before a predicted decrease and then purchasing them back the next time there is a predicted increase."}

# Generate plots
par(mfrow = c(3, 2), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
for(i in c(2, 5, 6)){
  
  # Offset numbers for indexing purposes
  if(i == 2){j <- 1}
  if(i == 5){j <- 2}
  if(i == 6){j <- 3}
  
  # Plot returns
  plot(returns.logreg(SPWeeklyLMod[[i]], data = SPWeeklyTest), type = "l", col = "blue", xaxt = "n",
       xlab = "Year", ylab = "Proportion of Initial Value", ylim = c(0, 8))
  axis(1, at = nrow(SPWeeklyTest)*(0:5)/5, labels = seq(2011, 2021, length.out = 6), cex.axis = 0.85)
  lines(returns.logreg(SPWeeklyLMod[[i]], data = SPWeeklyTest, lrisk = TRUE), col = "purple")
  lines(returns.logreg("none", data = SPWeeklyTest))
  text(x = rep(-8, 3)[j], y = rep(7.8, 3)[j], labels = c("Model 2", "Model 5", "Model 6")[j], adj = 0)
  
  # Plot increases/decreases on weeks when mode predicts a decrease
  glm.fit <- glm(SPWeeklyLMod[[i]], data = SPWeeklyTest, family = "binomial")
  glm.probs <- predict(glm.fit, SPWeeklyTest, type = "response")
  glm.pred <- rep("Down", length(glm.probs))
  glm.pred[glm.probs >= 0.5] <- "Up"
  plotdat <- data.frame(glm.pred, SPWeeklyTest$Direction, SPWeeklyTest$PctChange)
  plotdat <- subset(plotdat, glm.pred == "Down")
  plot(as.numeric(rownames(plotdat)), plotdat$SPWeeklyTest.PctChange, pch = 16, xaxt = "n",
       xlim = c(0, nrow(SPWeeklyTest)), col = ifelse(plotdat$SPWeeklyTest.PctChange < 0, "red", "green"),
       xlab = "Year", ylab = "Weekly Percent Change", ylim = c(-16, 16), cex.axis = 0.9)
  axis(1, at = nrow(SPWeeklyTest)*(0:5)/5, labels = seq(2011, 2021, length.out = 6), cex.axis = 0.85)
  abline(h = mean(plotdat$SPWeeklyTest.PctChange[plotdat$SPWeeklyTest.PctChange < 0]), lty = 2, col = "red")
  abline(h = mean(plotdat$SPWeeklyTest.PctChange[plotdat$SPWeeklyTest.PctChange > 0]), lty = 2, col = "green")
  text(x = rep(-8, 3)[j], y = rep(15, 3)[j], labels = c("Model 2", "Model 5", "Model 6")[j], adj = 0)
  text(x = rep(110, 3)[j], y = rep(15, 3)[j], labels = as.numeric(table(plotdat$SPWeeklyTest.Direction)[1]),
       col = "red", adj = 0)
  text(x = rep(140, 3)[j], y = rep(15, 3)[j], labels = "/", adj = 0)
  text(x = rep(150, 3)[j], y = rep(15, 3)[j], labels = as.numeric(table(plotdat$SPWeeklyTest.Direction)[2]),
       col = "green", adj = 0)}

```

\newpage

## Discriminant Analysis

Now that we have fit several logistic regression models and found two that performed particularly well, we can examine whether or not using a discriminant analysis approach can yield better-performing models. Because we are working an high-dimensional space, we cannot easily determine whether the decision boundary between the two observed classes (increase and decrease) is linear or nonlinear before fitting any sort of model. Thus, we try both linear discriminant analysis (LDA) and quadratic discriminant analysis (QDA), the former of which uses a linear decision boundary while the latter is more flexible and does not assume equal variance/covariance matrices between the two classes. We can then compare their performance and see which one, if any, is more suitable. The R syntax for the LDA and QDA approaches is very similar to that of using `glm` to fit a logistic model, this time using the functions `lda` and `qda` from the `MASS` package.

``` {r eval = FALSE, echo = TRUE}

# Linear discriminant analysis
lda(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + BVolume + Prev5GM + Prev5Pct,
    data = SPWeeklyTrain)

# Quadratic discriminant analysis
qda(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + BVolume + Prev5GM + Prev5Pct,
    data = SPWeeklyTrain)

```

Just like earlier, there are 255 possible non-interactive models that we can fit, and it is computationally feasible to evaluate every single one of these models. We can build a function `damod.comb`, which is almost identical to `logreg.comb` in terms of functionality, that evaluates each possible model on the training data set and returns a specified statistic such as accuracy, sensitivity, specificity, positive predictive value, or negative predictive value.

``` {r eval = FALSE, echo = TRUE}

damod.comb <- function(dataTrain, daType, output, n){
  combn(names(dataTrain)[-c(2:3)], n) %>% 
    apply(FUN = paste0, MARGIN = 2, collapse = "+") %>% 
    paste0("Direction~", .) %>%
    sapply(formula) %>% 
    sapply(FUN = damod, dataTrain = dataTrain, daType = daType, output = output) %>% 
    sort() %>%
    return()}

```

We then use this function to select the non-interactive model with the highest training accuracy, first specifying an LDA model for the `daType` argument. This model, which we will call **Model 1**, has an overall training accuracy of approximately 57.62% and correctly predicts 749 out of 1662 movements using a linear combination of the predictors `BVolume`, `Prev5Pct`, `Lag2`, `Lag3`, and `Lag5`. We can also maximise accuracy using this function but by fitting a QDA model rather than an LDA model; doing so yields a model with a slightly higher training accuracy of 58.23%, which we will call **Model 2**. This model only uses the predictors `Prev5GM`, `Lag1`, `Lag3` and `Lag4`.

As we did before with our non-interactive logistic regression models, we can also select LDA/QDA models by maximising PPV rather than accuracy. Doing so gives us an LDA model with a PPV of 57.53% and the exact same structure as Model 1; we will call this **Model 3**. We also obtain a QDA model with a PPV of 59.34%; we will call this **Model 4**; this model has the same predictor variables as Model 2, but with the addition of `BVolume` and `Prev5Pct`.

If we wish to also examine the effectiveness of interactive models, we face the same problem as we did earlier; there are simply too many possible models to evaluate every single one, as we do not have the computational resources to fit and test 68719476735 different models. Thus, rather than identifying a global maximum with certainty, we must perform a heuristic search to maximise accuracy or PPV and hope that we can identify the global maximum, or a local maximum that is approximately equal. Here we use an almost identical version of the forward and backward search algorithms employed on the logistic models, though adapting them to use `lda` and `qda` rather than `glm`.

``` {r eval = FALSE, echo = TRUE}

# Function to remove a term and find new accuracy
damod.lcv1 <- function(i, dataTrain, daType, output){
  predVec[-i] %>% 
    paste0(., collapse = "+") %>% 
    paste0("Direction~", .) %>%
    formula() %>% 
    damod(dataTrain = SPWeeklyTrain, daType = daType, output = output) %>% 
    return()}

# Function to return accuracy and new list of predictors after removing a predictor
damod.bwd <- function(predVec, daType, output){
  accs <- sapply(1:length(predVec), FUN = damod.lcv1, dataTrain = SPWeeklyTrain,
                 daType = daType, output = output)
  pv <- predVec[-which.max(accs)]
  return(list(predVec = pv, maxacc = max(accs)))}

# Function to add a term and find new accuracy
damod.lcv2 <- function(i, dataTrain, daType, output){
  c(predVecFwd, predVecRemain[i]) %>% 
  paste0(., collapse = "+") %>% 
    paste0("Direction~", .) %>%
    formula() %>%
    damod(dataTrain = SPWeeklyTrain, daType = daType, output = output) %>% 
    return()}

# Function to return accuracy and new list of predictors after adding a predictor
damod.fwd <- function(predVecRemain, predVecFwd, daType, output){
  accs <- sapply(1:length(predVecRemain), FUN = damod.lcv2, dataTrain = SPWeeklyTrain,
                 daType = daType, output = output)
  pvf <- c(predVecFwd, predVecRemain[which.max(accs)])
  pvr <- predVecRemain[-which.max(accs)]
  return(list(predVecFwd = pvf, predVecRemain = pvr, maxacc = max(accs)))}

```

These functions operate the same as before; the backward-step algorithm starts with a full model and removes terms until accuracy or PPV is maximised, while the forward-step algorith starts with a null model and adds terms until accuracy or PPV is maximised. If we then use these functions to maximise accuracy on an LDA model, we get a 29-term **Model 5** with 59.15% accuracy that was chosen using backward selection and a 8-term **Model 6** with 57.54% accuracy that was chosen using forward selection. We can then apply these functions by maximising accuracy on an QDA model rather than an LDA model, we get a 31-term **Model 7** with 59.46% accuracy that was chosen using backward selection and a 10-term **Model 8** with 58.92% accuracy that was chosen using forward selection.

After using the forward and backward selection algorithms to maximise accuracy, we then use them to maximise PPV. If we use these functions to maximise PPV on an LDA model, we get a 29-term **Model 9** with 59.38% accuracy that was chosen using backward selection and a 8-term **Model 10** with 57.92% accuracy that was chosen using forward selection. We can then apply these functions by maximising PPV on an QDA model rather than an LDA model, we get a 18-term **Model 11** with 49.23% accuracy that was chosen using backward selection and a 13-term **Model 12** with 49.69% accuracy that was chosen using forward selection. Note that unlike the other models, Model 12 and Model 13 have an accuracy of less than 50%, which is worse than simply guessing.

``` {r include = FALSE}

# Function to perform discriminant analysis and output predictive accuracy
damod <- function(formula, dataTrain, daType, output){
  
  # Fit linear or quadratic discriminant analysis using training data
  if(daType == "lda"){
    da.fit <- lda(formula, data = dataTrain)}
  if(daType == "qda"){
    da.fit <- qda(formula, data = dataTrain)}
  
  # Classify training data; get posterior probabilities
  da.pred <- predict(da.fit, dataTrain)$class
  
  # Confusion matrix of classified observations
  # Must manually add Down row if model never predicts Down
  confMatrix <- table(da.pred, dataTrain$Direction)
  if(nrow(confMatrix) == 1){
    confMatrix <- rbind(c(0, 0), confMatrix)}
  rownames(confMatrix) <- c("[P]Down", "[P]Up")
  colnames(confMatrix) <- c("[O]Down", "[O]Up")
  
  # Overall predictive accuracy
  accuracy <- sum(diag(confMatrix)/sum(confMatrix))
  
  # Sensitivity and specificity
  specificity <- confMatrix[1, 1]/sum(confMatrix[, 1])
  sensitivity <- confMatrix[2, 2]/sum(confMatrix[, 2])
  
  # Positive and negative predictive value
  npv <- confMatrix[1, 1]/sum(confMatrix[1, ])
  ppv <- confMatrix[2, 2]/sum(confMatrix[2, ])
  
  # Return individual outputs or list of all outputs
  if(output == "all"){
    return(list(confMatrix = confMatrix, accuracy = accuracy, specificity = specificity,
              sensitivity = sensitivity, npv = npv, ppv = ppv))}
  if(output == "confMatrix"){
    return(confMatrix)}
  if(output == "accuracy"){
    return(accuracy)}
  if(output == "specificity"){
    return(specificity)}
  if(output == "sensitivity"){
    return(sensitivity)}
  if(output == "npv"){
    return(npv)}
  if(output == "ppv"){
    return(ppv)}}

```

``` {r include = FALSE}

# Function to fit logistic regression to all possible combinations of n variables
# Outputs value and combination of variables for desired prediction metric
damod.comb <- function(dataTrain, daType, output, n){
  combn(names(dataTrain)[-c(2:3)], n) %>% 
    apply(FUN = paste0, MARGIN = 2, collapse = "+") %>% 
    paste0("Direction~", .) %>%
    sapply(formula) %>% 
    sapply(FUN = damod, dataTrain = dataTrain, daType = daType, output = output) %>% 
    sort() %>%
    return()}

# Create empty list to populate with top models
SPWeeklyDMod <- list()

# Find top 10 models for accuracy: LDA
SPWeeklyTop <- unlist(sapply(1:8, FUN = damod.comb, dataTrain = SPWeeklyTrain, daType = "lda", output = "accuracy"))
sort(SPWeeklyTop, decreasing = TRUE)[1:10]
SPWeeklyDMod[[1]] <- names(sort(SPWeeklyTop, decreasing = TRUE)[1])
damod(formula(SPWeeklyDMod[[1]]), dataTrain = SPWeeklyTrain, daType = "lda", output = "confMatrix")

# Find top 10 models for accuracy: QDA
SPWeeklyTop <- unlist(sapply(1:8, FUN = damod.comb, dataTrain = SPWeeklyTrain, daType = "qda", output = "accuracy"))
sort(SPWeeklyTop, decreasing = TRUE)[1:10]
SPWeeklyDMod[[2]] <- names(sort(SPWeeklyTop, decreasing = TRUE)[1])
damod(formula(SPWeeklyDMod[[2]]), dataTrain = SPWeeklyTrain, daType = "qda", output = "confMatrix")

# Find top 10 models for ppv: LDA
SPWeeklyTop <- unlist(sapply(1:8, FUN = damod.comb, dataTrain = SPWeeklyTrain, daType = "lda", output = "ppv"))
sort(SPWeeklyTop, decreasing = TRUE)[1:10]
SPWeeklyDMod[[3]] <- names(sort(SPWeeklyTop, decreasing = TRUE)[1])
damod(formula(SPWeeklyDMod[[3]]), dataTrain = SPWeeklyTrain, daType = "lda", output = "confMatrix")

# Find top 10 models for ppv: QDA
SPWeeklyTop <- unlist(sapply(1:8, FUN = damod.comb, dataTrain = SPWeeklyTrain, daType = "qda", output = "ppv"))
sort(SPWeeklyTop, decreasing = TRUE)[1:10]
SPWeeklyDMod[[4]] <- names(sort(SPWeeklyTop, decreasing = TRUE)[1])
damod(formula(SPWeeklyDMod[[4]]), dataTrain = SPWeeklyTrain, daType = "qda", output = "confMatrix")

# Find top 10 models for npv
SPWeeklyTop <- unlist(sapply(1:8, FUN = damod.comb, dataTrain = SPWeeklyTrain, daType = "lda", output = "npv"))
sort(SPWeeklyTop, decreasing = TRUE)[1:10]
logreg(names(sort(SPWeeklyTop, decreasing = TRUE))[1], dataTrain = SPWeeklyTrain, output = "confMatrix")

# Remove variables from global environment
remove(SPWeeklyTop)

```

``` {r include = FALSE}

# Function to remove a term and find new accuracy
damod.lcv1 <- function(i, dataTrain, daType, output){
  predVec[-i] %>% 
    paste0(., collapse = "+") %>% 
    paste0("Direction~", .) %>%
    formula() %>% 
    damod(dataTrain = SPWeeklyTrain, daType = daType, output = output) %>% 
    return()}

# Function to return accuracy and new list of predictors after removing a predictor
damod.bwd <- function(predVec, daType, output){
  accs <- sapply(1:length(predVec), FUN = damod.lcv1, dataTrain = SPWeeklyTrain, daType = daType, output = output)
  pv <- predVec[-which.max(accs)]
  return(list(predVec = pv, maxacc = max(accs)))}

# Function to add a term and find new accuracy
damod.lcv2 <- function(i, dataTrain, daType, output){
  c(predVecFwd, predVecRemain[i]) %>% 
  paste0(., collapse = "+") %>% 
    paste0("Direction~", .) %>%
    formula() %>%
    damod(dataTrain = SPWeeklyTrain, daType = daType, output = output) %>% 
    return()}

# Function to return accuracy and new list of predictors after adding a predictor
damod.fwd <- function(predVecRemain, predVecFwd, daType, output){
  accs <- sapply(1:length(predVecRemain), FUN = damod.lcv2, dataTrain = SPWeeklyTrain,
                 daType = daType, output = output)
  pvf <- c(predVecFwd, predVecRemain[which.max(accs)])
  pvr <- predVecRemain[-which.max(accs)]
  return(list(predVecFwd = pvf, predVecRemain = pvr, maxacc = max(accs)))}

# Apply backward step algorithm using accuracy: LDA
combn(names(SPWeeklyTrain)[-c(2:3)], 2) %>%
    apply(FUN = paste0, MARGIN = 2, collapse = ":") %>%
    c(names(SPWeeklyTrain)[-c(2:3)]) -> predVec
prevmaxacc <- c(0.5, 0.5)
maxacc <- damod.bwd(predVec, "lda", "accuracy")$maxacc
predVec <- damod.bwd(predVec, "lda", "accuracy")$predVec
prevmaxacc <- c(prevmaxacc, maxacc)
while(length(predVec) > 1){
  maxacc <- damod.bwd(predVec, "lda", "accuracy")$maxacc
  if(maxacc < prevmaxacc[length(prevmaxacc) - 1]){
    break}
  predVec <- damod.bwd(predVec, "lda", "accuracy")$predVec
  prevmaxacc <- c(prevmaxacc, maxacc)}
prevmaxacc[length(prevmaxacc)]
SPWeeklyDMod[[5]] <- paste0("Direction~", paste0(predVec, collapse = "+"))

# Apply forward step algorithm using accuracy: LDA
combn(names(SPWeeklyTrain)[-c(2:3)], 2) %>%
    apply(FUN = paste0, MARGIN = 2, collapse = ":") %>%
    c(names(SPWeeklyTrain)[-c(2:3)]) -> predVecRemain
prevmaxacc <- c(0.5, 0.5)
predVecFwd <- c()
maxacc <- damod.fwd(predVecRemain, predVecFwd, "lda", "accuracy")$maxacc
predVecFwd <- damod.fwd(predVecRemain, predVecFwd, "lda", "accuracy")$predVecFwd
predVecRemain <- predVecRemain[predVecRemain != predVecFwd[length(predVecFwd)]]
prevmaxacc <- c(prevmaxacc, maxacc)
while(length(predVecFwd) < 36){
  maxacc <- damod.fwd(predVecRemain, predVecFwd, "lda", "accuracy")$maxacc
  if(maxacc < prevmaxacc[length(prevmaxacc) - 1]){
    break}
  predVecFwd <- damod.fwd(predVecRemain, predVecFwd, "lda", "accuracy")$predVecFwd
  predVecRemain <- predVecRemain[predVecRemain != predVecFwd[length(predVecFwd)]]
  prevmaxacc <- c(prevmaxacc, maxacc)}
prevmaxacc[length(prevmaxacc)]
SPWeeklyDMod[[6]] <- paste0("Direction~", paste0(predVecFwd, collapse = "+"))

# Apply backward step algorithm using accuracy: QDA
combn(names(SPWeeklyTrain)[-c(2:3)], 2) %>%
    apply(FUN = paste0, MARGIN = 2, collapse = ":") %>%
    c(names(SPWeeklyTrain)[-c(2:3)]) -> predVec
prevmaxacc <- c(0.5, 0.5)
maxacc <- damod.bwd(predVec, "qda", "accuracy")$maxacc
predVec <- damod.bwd(predVec, "qda", "accuracy")$predVec
prevmaxacc <- c(prevmaxacc, maxacc)
while(length(predVec) > 1){
  maxacc <- damod.bwd(predVec, "qda", "accuracy")$maxacc
  if(maxacc < prevmaxacc[length(prevmaxacc) - 1]){
    break}
  predVec <- damod.bwd(predVec, "qda", "accuracy")$predVec
  prevmaxacc <- c(prevmaxacc, maxacc)}
prevmaxacc[length(prevmaxacc)]
SPWeeklyDMod[[7]] <- paste0("Direction~", paste0(predVec, collapse = "+"))

# Apply forward step algorithm using accuracy: QDA
combn(names(SPWeeklyTrain)[-c(2:3)], 2) %>%
    apply(FUN = paste0, MARGIN = 2, collapse = ":") %>%
    c(names(SPWeeklyTrain)[-c(2:3)]) -> predVecRemain
prevmaxacc <- c(0.5, 0.5)
predVecFwd <- c()
maxacc <- damod.fwd(predVecRemain, predVecFwd, "qda", "accuracy")$maxacc
predVecFwd <- damod.fwd(predVecRemain, predVecFwd, "qda", "accuracy")$predVecFwd
predVecRemain <- predVecRemain[predVecRemain != predVecFwd[length(predVecFwd)]]
prevmaxacc <- c(prevmaxacc, maxacc)
while(length(predVecFwd) < 36){
  maxacc <- damod.fwd(predVecRemain, predVecFwd, "qda", "accuracy")$maxacc
  if(maxacc < prevmaxacc[length(prevmaxacc) - 1]){
    break}
  predVecFwd <- damod.fwd(predVecRemain, predVecFwd, "qda", "accuracy")$predVecFwd
  predVecRemain <- predVecRemain[predVecRemain != predVecFwd[length(predVecFwd)]]
  prevmaxacc <- c(prevmaxacc, maxacc)}
prevmaxacc[length(prevmaxacc)]
SPWeeklyDMod[[8]] <- paste0("Direction~", paste0(predVecFwd, collapse = "+"))

# Apply backward step algorithm using PPV: LDA
combn(names(SPWeeklyTrain)[-c(2:3)], 2) %>%
    apply(FUN = paste0, MARGIN = 2, collapse = ":") %>%
    c(names(SPWeeklyTrain)[-c(2:3)]) -> predVec
prevmaxacc <- c(0.5, 0.5)
maxacc <- damod.bwd(predVec, "lda", "ppv")$maxacc
predVec <- damod.bwd(predVec, "lda", "ppv")$predVec
prevmaxacc <- c(prevmaxacc, maxacc)
while(length(predVec) > 1){
  maxacc <- damod.bwd(predVec, "lda", "ppv")$maxacc
  if(maxacc < prevmaxacc[length(prevmaxacc) - 1]){
    break}
  predVec <- damod.bwd(predVec, "lda", "ppv")$predVec
  prevmaxacc <- c(prevmaxacc, maxacc)}
prevmaxacc[length(prevmaxacc)]
SPWeeklyDMod[[9]] <- paste0("Direction~", paste0(predVec, collapse = "+"))

# Apply forward step algorithm using PPV: LDA
combn(names(SPWeeklyTrain)[-c(2:3)], 2) %>%
    apply(FUN = paste0, MARGIN = 2, collapse = ":") %>%
    c(names(SPWeeklyTrain)[-c(2:3)]) -> predVecRemain
prevmaxacc <- c(0.5, 0.5)
predVecFwd <- c()
maxacc <- damod.fwd(predVecRemain, predVecFwd, "lda", "ppv")$maxacc
predVecFwd <- damod.fwd(predVecRemain, predVecFwd, "lda", "ppv")$predVecFwd
predVecRemain <- predVecRemain[predVecRemain != predVecFwd[length(predVecFwd)]]
prevmaxacc <- c(prevmaxacc, maxacc)
while(length(predVecFwd) < 36){
  maxacc <- damod.fwd(predVecRemain, predVecFwd, "lda", "ppv")$maxacc
  if(maxacc < prevmaxacc[length(prevmaxacc) - 1]){
    break}
  predVecFwd <- damod.fwd(predVecRemain, predVecFwd, "lda", "ppv")$predVecFwd
  predVecRemain <- predVecRemain[predVecRemain != predVecFwd[length(predVecFwd)]]
  prevmaxacc <- c(prevmaxacc, maxacc)}
prevmaxacc[length(prevmaxacc)]
SPWeeklyDMod[[10]] <- paste0("Direction~", paste0(predVecFwd, collapse = "+"))

# Apply backward step algorithm using PPV: QDA
combn(names(SPWeeklyTrain)[-c(2:3)], 2) %>%
    apply(FUN = paste0, MARGIN = 2, collapse = ":") %>%
    c(names(SPWeeklyTrain)[-c(2:3)]) -> predVec
prevmaxacc <- c(0.5, 0.5)
maxacc <- damod.bwd(predVec, "qda", "ppv")$maxacc
predVec <- damod.bwd(predVec, "qda", "ppv")$predVec
prevmaxacc <- c(prevmaxacc, maxacc)
while(length(predVec) > 1){
  maxacc <- damod.bwd(predVec, "qda", "ppv")$maxacc
  if(maxacc < prevmaxacc[length(prevmaxacc) - 1]){
    break}
  predVec <- damod.bwd(predVec, "qda", "ppv")$predVec
  prevmaxacc <- c(prevmaxacc, maxacc)}
prevmaxacc[length(prevmaxacc)]
SPWeeklyDMod[[11]] <- paste0("Direction~", paste0(predVec, collapse = "+"))

# Apply forward step algorithm using PPV: QDA
combn(names(SPWeeklyTrain)[-c(2:3)], 2) %>%
    apply(FUN = paste0, MARGIN = 2, collapse = ":") %>%
    c(names(SPWeeklyTrain)[-c(2:3)]) -> predVecRemain
prevmaxacc <- c(0.5, 0.5)
predVecFwd <- c()
maxacc <- damod.fwd(predVecRemain, predVecFwd, "qda", "ppv")$maxacc
predVecFwd <- damod.fwd(predVecRemain, predVecFwd, "qda", "ppv")$predVecFwd
predVecRemain <- predVecRemain[predVecRemain != predVecFwd[length(predVecFwd)]]
prevmaxacc <- c(prevmaxacc, maxacc)
while(length(predVecFwd) < 36){
  maxacc <- damod.fwd(predVecRemain, predVecFwd, "qda", "ppv")$maxacc
  if(maxacc < prevmaxacc[length(prevmaxacc) - 1]){
    break}
  predVecFwd <- damod.fwd(predVecRemain, predVecFwd, "qda", "ppv")$predVecFwd
  predVecRemain <- predVecRemain[predVecRemain != predVecFwd[length(predVecFwd)]]
  prevmaxacc <- c(prevmaxacc, maxacc)}
prevmaxacc[length(prevmaxacc)]
SPWeeklyDMod[[12]] <- paste0("Direction~", paste0(predVecFwd, collapse = "+"))

# Remove variables from global environment
remove(maxacc, predVec, predVecFwd, predVecRemain, prevmaxacc)

```

``` {r include = FALSE}

# Compare model test accuracy (LDA)
SPWeeklyDMod[c(1, 3, 5, 6, 9, 10)] %>% 
  sapply(formula) %>% 
  sapply(FUN = damod, dataTrain = SPWeeklyTest, daType = "lda", output = "accuracy")

# Compare model test accuracy (QDA)
SPWeeklyDMod[c(2, 4, 7, 8, 11, 12)] %>% 
  sapply(formula) %>% 
  sapply(FUN = damod, dataTrain = SPWeeklyTest, daType = "qda", output = "accuracy")

# Compare model test PPV (LDA)
SPWeeklyDMod[c(1, 3, 5, 6, 9, 10)] %>% 
  sapply(formula) %>% 
  sapply(FUN = damod, dataTrain = SPWeeklyTest, daType = "lda", output = "ppv")

# Compare model test PPV (QDA)
SPWeeklyDMod[c(2, 4, 7, 8, 11, 12)] %>% 
  sapply(formula) %>% 
  sapply(FUN = damod, dataTrain = SPWeeklyTest, daType = "qda", output = "ppv")

# Function to estimate total return on model vs no model
# Assumes complete liquidation of assets prior to predicted decrease
# Setting lrisk to TRUE liquidates only 35% of assets prior to predicted decrease
returns.damod <- function(formula, data, daType, final = FALSE, lrisk = FALSE){
  if(formula != "none"){
    if(daType == "lda"){
      da.fit <- lda(formula = formula(formula), data = data)}
    if(daType == "qda"){
      da.fit <- qda(formula = formula(formula), data = data)}
    da.pred <- predict(da.fit, data)$class
    pcts <- data$PctChange
    if(lrisk == FALSE){
      pcts[da.pred == "Down"] <- 0}
    if(lrisk == TRUE){
      pcts[da.pred == "Down"] <- pcts[da.pred == "Down"]*0.65}
    totalReturn <- c()
    for(i in 1:length(pcts)){
      totalReturn <- c(totalReturn, prod((pcts[1:i]/100)+1))}}
  if(formula == "none"){
    totalReturn <- c()
    for(i in 1:nrow(data)){
      totalReturn <- c(totalReturn, prod((data$PctChange[1:i]/100)+1))}}
  ifelse(final == TRUE, return(totalReturn[length(totalReturn)]), return(totalReturn))}

# Compare lifetime returns (LDA); use loop since sapply doesn't work for some reason
for(i in c(1, 3, 5, 6, 9, 10)){
  print(returns.damod(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest, daType = "lda", final = TRUE))}

# Compare lifetime returns (QDA); use loop since sapply doesn't work for some reason
for(i in c(2, 4, 7, 8, 11, 12)){
  print(returns.damod(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest, daType = "lda", final = TRUE))}

```

``` {r Figure25, fig.height = 8.3, warning = FALSE, message = FALSE, fig.cap = "\\label{fig:Figure25} ROC curves for the LDA models selected by maximising accuracy. Accuracy, positive predictive value (PPV), and area under the curve (AUC) are listed for each plot; the red dot represents model sensitivity and specificity."}

par(mfrow = c(3, 2))

for(i in c(1, 5, 6)){
  
  if(i == 1){j <- 1}
  if(i == 5){j <- 2}
  if(i == 6){j <- 3}
  
  da.stats <- sapply(c("accuracy", "sensitivity", "specificity", "ppv"),
                      FUN = damod, formula = formula(SPWeeklyDMod[[i]]), daType = "lda", dataTrain = SPWeeklyTrain)
  da.fit <- lda(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTrain)
  da.probs <- predict(da.fit, SPWeeklyTrain)$posterior
  auc <- roc(SPWeeklyTrain$Direction, da.probs[, 2], direction = "<")$auc
  roc(SPWeeklyTrain$Direction, da.probs[, 2], plot = TRUE, direction = "<", mar = c(4, 4, 1, 2) + 0.1)
  text(x = rep(1.1, 3)[j], y = rep(0.98, 3)[j],
       labels = c("Model 1: Train", "Model 5: Train", "Model 6: Train")[j], adj = 0)
  text(x = rep(1.1, 3), y = c(0.9, 0.83, 0.76), labels = c("Acc:", "PPV:", "AUC:"), adj = 0)
  text(x = rep(0.94, 3), y = c(0.9, 0.83, 0.76), labels = round(as.numeric(c(da.stats[c(1, 4)], auc)), 4), adj = 0)
  points(x = da.stats[3], y = da.stats[2], col = "red", pch = 16)
  
  da.stats <- sapply(c("accuracy", "sensitivity", "specificity", "ppv"),
                      FUN = damod, formula = formula(SPWeeklyDMod[[i]]), daType = "lda", dataTrain = SPWeeklyTest)
  da.fit <- lda(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest)
  da.probs <- predict(da.fit, SPWeeklyTest)$posterior
  auc <- roc(SPWeeklyTest$Direction, da.probs[, 2], direction = "<")$auc
  roc(SPWeeklyTest$Direction, da.probs[, 2], plot = TRUE, direction = "<", mar = c(4, 4, 1, 2) + 0.1)
  text(x = rep(1.1, 3)[j], y = rep(0.98, 3)[j],
       labels = c("Model 1: Test", "Model 5: Test", "Model 6: Test")[j], adj = 0)
  text(x = rep(1.1, 3), y = c(0.9, 0.83, 0.76), labels = c("Acc:", "PPV:", "AUC:"), adj = 0)
  text(x = rep(0.94, 3), y = c(0.9, 0.83, 0.76), labels = round(as.numeric(c(da.stats[c(1, 4)], auc)), 4), adj = 0)
  points(x = da.stats[3], y = da.stats[2], col = "red", pch = 16)}

```

``` {r Figure26, fig.height = 8.3, warning = FALSE, message = FALSE, fig.cap = "\\label{fig:Figure26} ROC curves for the QDA models selected by maximising accuracy. Accuracy, positive predictive value (PPV), and area under the curve (AUC) are listed for each plot; the red dot represents model sensitivity and specificity."}

par(mfrow = c(3, 2))

for(i in c(2, 7, 8)){
  
  if(i == 2){j <- 1}
  if(i == 7){j <- 2}
  if(i == 8){j <- 3}
  
  da.stats <- sapply(c("accuracy", "sensitivity", "specificity", "ppv"),
                      FUN = damod, formula = formula(SPWeeklyDMod[[i]]), daType = "qda", dataTrain = SPWeeklyTrain)
  da.fit <- qda(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTrain)
  da.probs <- predict(da.fit, SPWeeklyTrain)$posterior
  auc <- roc(SPWeeklyTrain$Direction, da.probs[, 2], direction = "<")$auc
  roc(SPWeeklyTrain$Direction, da.probs[, 2], plot = TRUE, direction = "<", mar = c(4, 4, 1, 2) + 0.1)
  text(x = rep(1.1, 3)[j], y = rep(0.98, 3)[j],
       labels = c("Model 2: Train", "Model 7: Train", "Model 8: Train")[j], adj = 0)
  text(x = rep(1.1, 3), y = c(0.9, 0.83, 0.76), labels = c("Acc:", "PPV:", "AUC:"), adj = 0)
  text(x = rep(0.94, 3), y = c(0.9, 0.83, 0.76), labels = round(as.numeric(c(da.stats[c(1, 4)], auc)), 4), adj = 0)
  points(x = da.stats[3], y = da.stats[2], col = "red", pch = 16)
  
  da.stats <- sapply(c("accuracy", "sensitivity", "specificity", "ppv"),
                      FUN = damod, formula = formula(SPWeeklyDMod[[i]]), daType = "qda", dataTrain = SPWeeklyTest)
  da.fit <- qda(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest)
  da.probs <- predict(da.fit, SPWeeklyTest)$posterior
  auc <- roc(SPWeeklyTest$Direction, da.probs[, 2], direction = "<")$auc
  roc(SPWeeklyTest$Direction, da.probs[, 2], plot = TRUE, direction = "<", mar = c(4, 4, 1, 2) + 0.1)
  text(x = rep(1.1, 3)[j], y = rep(0.98, 3)[j],
       labels = c("Model 2: Test", "Model 7: Test", "Model 8: Test")[j], adj = 0)
  text(x = rep(1.1, 3), y = c(0.9, 0.83, 0.76), labels = c("Acc:", "PPV:", "AUC:"), adj = 0)
  text(x = rep(0.94, 3), y = c(0.9, 0.83, 0.76), labels = round(as.numeric(c(da.stats[c(1, 4)], auc)), 4), adj = 0)
  points(x = da.stats[3], y = da.stats[2], col = "red", pch = 16)}

```

``` {r Figure27, fig.height = 8.3, warning = FALSE, message = FALSE, fig.cap = "\\label{fig:Figure27} ROC curves for the LDA models selected by maximising PPV. Accuracy, positive predictive value (PPV), and area under the curve (AUC) are listed for each plot; the red dot represents model sensitivity and specificity."}

par(mfrow = c(3, 2))

for(i in c(3, 9, 10)){
  
  if(i == 3){j <- 1}
  if(i == 9){j <- 2}
  if(i == 10){j <- 3}
  
  da.stats <- sapply(c("accuracy", "sensitivity", "specificity", "ppv"),
                      FUN = damod, formula = formula(SPWeeklyDMod[[i]]), daType = "lda", dataTrain = SPWeeklyTrain)
  da.fit <- lda(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTrain)
  da.probs <- predict(da.fit, SPWeeklyTrain)$posterior
  auc <- roc(SPWeeklyTrain$Direction, da.probs[, 2], direction = "<")$auc
  roc(SPWeeklyTrain$Direction, da.probs[, 2], plot = TRUE, direction = "<", mar = c(4, 4, 1, 2) + 0.1)
  text(x = rep(1.1, 3)[j], y = rep(0.98, 3)[j],
       labels = c("Model 3: Train", "Model 9: Train", "Model 10: Train")[j], adj = 0)
  text(x = rep(1.1, 3), y = c(0.9, 0.83, 0.76), labels = c("Acc:", "PPV:", "AUC:"), adj = 0)
  text(x = rep(0.94, 3), y = c(0.9, 0.83, 0.76), labels = round(as.numeric(c(da.stats[c(1, 4)], auc)), 4), adj = 0)
  points(x = da.stats[3], y = da.stats[2], col = "red", pch = 16)
  
  da.stats <- sapply(c("accuracy", "sensitivity", "specificity", "ppv"),
                      FUN = damod, formula = formula(SPWeeklyDMod[[i]]), daType = "lda", dataTrain = SPWeeklyTest)
  da.fit <- lda(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest)
  da.probs <- predict(da.fit, SPWeeklyTest)$posterior
  auc <- roc(SPWeeklyTest$Direction, da.probs[, 2], direction = "<")$auc
  roc(SPWeeklyTest$Direction, da.probs[, 2], plot = TRUE, direction = "<", mar = c(4, 4, 1, 2) + 0.1)
  text(x = rep(1.1, 3)[j], y = rep(0.98, 3)[j],
       labels = c("Model 3: Test", "Model 9: Test", "Model 10: Test")[j], adj = 0)
  text(x = rep(1.1, 3), y = c(0.9, 0.83, 0.76), labels = c("Acc:", "PPV:", "AUC:"), adj = 0)
  text(x = rep(0.94, 3), y = c(0.9, 0.83, 0.76), labels = round(as.numeric(c(da.stats[c(1, 4)], auc)), 4), adj = 0)
  points(x = da.stats[3], y = da.stats[2], col = "red", pch = 16)}

```

``` {r Figure28, fig.height = 8.3, warning = FALSE, message = FALSE, fig.cap = "\\label{fig:Figure28} ROC curves for the QDA models selected by maximising PPV. Accuracy, positive predictive value (PPV), and area under the curve (AUC) are listed for each plot; the red dot represents model sensitivity and specificity."}

par(mfrow = c(3, 2))

for(i in c(4, 11, 12)){
  
  if(i == 4){j <- 1}
  if(i == 11){j <- 2}
  if(i == 12){j <- 3}
  
  da.stats <- sapply(c("accuracy", "sensitivity", "specificity", "ppv"),
                      FUN = damod, formula = formula(SPWeeklyDMod[[i]]), daType = "qda", dataTrain = SPWeeklyTrain)
  da.fit <- qda(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTrain)
  da.probs <- predict(da.fit, SPWeeklyTrain)$posterior
  auc <- roc(SPWeeklyTrain$Direction, da.probs[, 2], direction = "<")$auc
  roc(SPWeeklyTrain$Direction, da.probs[, 2], plot = TRUE, direction = "<", mar = c(4, 4, 1, 2) + 0.1)
  text(x = rep(1.1, 3)[j], y = rep(0.98, 3)[j],
       labels = c("Model 4: Train", "Model 11: Train", "Model 12: Train")[j], adj = 0)
  text(x = rep(1.1, 3), y = c(0.9, 0.83, 0.76), labels = c("Acc:", "PPV:", "AUC:"), adj = 0)
  text(x = rep(0.94, 3), y = c(0.9, 0.83, 0.76), labels = round(as.numeric(c(da.stats[c(1, 4)], auc)), 4), adj = 0)
  points(x = da.stats[3], y = da.stats[2], col = "red", pch = 16)
  
  da.stats <- sapply(c("accuracy", "sensitivity", "specificity", "ppv"),
                      FUN = damod, formula = formula(SPWeeklyDMod[[i]]), daType = "qda", dataTrain = SPWeeklyTest)
  da.fit <- qda(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest)
  da.probs <- predict(da.fit, SPWeeklyTest)$posterior
  auc <- roc(SPWeeklyTest$Direction, da.probs[, 2], direction = "<")$auc
  roc(SPWeeklyTest$Direction, da.probs[, 2], plot = TRUE, direction = "<", mar = c(4, 4, 1, 2) + 0.1)
  text(x = rep(1.1, 3)[j], y = rep(0.98, 3)[j],
       labels = c("Model 4: Test", "Model 11: Test", "Model 12: Test")[j], adj = 0)
  text(x = rep(1.1, 3), y = c(0.9, 0.83, 0.76), labels = c("Acc:", "PPV:", "AUC:"), adj = 0)
  text(x = rep(0.94, 3), y = c(0.9, 0.83, 0.76), labels = round(as.numeric(c(da.stats[c(1, 4)], auc)), 4), adj = 0)
  points(x = da.stats[3], y = da.stats[2], col = "red", pch = 16)}

```

``` {r Figure29, fig.height = 7.8, warning = FALSE, fig.cap = "\\label{fig:Figure29} Relative value of the S\\&P 500 from 2011-2021 (left) and percent change for weeks in 2011-2021 for which an increase was not predicted (right) based on LDA models fit to the 1986-2010 data; the three models here were selected using accuracy. The black line represents a buy-and-hold strategy, while the blue line represents a strategy of selling all assets before a predicted decrease and then purchasing them back the next time there is a predicted increase. The purple line represents a less risky strategy of only selling 35\\% of assets before a predicted decrease and then purchasing them back the next time there is a predicted increase."}

# Generate plots
par(mfrow = c(3, 2), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
for(i in c(1, 5, 6)){
  
  # Offset numbers for indexing purposes
  if(i == 1){j <- 1}
  if(i == 5){j <- 2}
  if(i == 6){j <- 3}
  
  # Plot returns
  plot(returns.damod(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest, daType = "lda"), type = "l",
       col = "blue", xaxt = "n", xlab = "Year", ylab = "Proportion of Initial Value", ylim = c(0, 8))
  axis(1, at = nrow(SPWeeklyTest)*(0:5)/5, labels = seq(2011, 2021, length.out = 6), cex.axis = 0.85)
  lines(returns.damod(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest, daType = "lda", lrisk = TRUE), col = "purple")
  lines(returns.damod("none", data = SPWeeklyTest))
  text(x = rep(-8, 3)[j], y = rep(7.8, 3)[j], labels = c("Model 1", "Model 5", "Model 6")[j], adj = 0)
  
  # Plot increases/decreases on weeks when mode predicts a decrease
  da.fit <- lda(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest)
  da.pred <- predict(da.fit, SPWeeklyTest)$class
  plotdat <- data.frame(da.pred, SPWeeklyTest$Direction, SPWeeklyTest$PctChange)
  plotdat <- subset(plotdat, da.pred == "Down")
  plot(as.numeric(rownames(plotdat)), plotdat$SPWeeklyTest.PctChange, pch = 16, xaxt = "n",
       xlim = c(0, nrow(SPWeeklyTest)), col = ifelse(plotdat$SPWeeklyTest.PctChange < 0, "red", "green"),
       xlab = "Year", ylab = "Weekly Percent Change", ylim = c(-16, 16), cex.axis = 0.9)
  axis(1, at = nrow(SPWeeklyTest)*(0:5)/5, labels = seq(2011, 2021, length.out = 6), cex.axis = 0.85)
  abline(h = mean(plotdat$SPWeeklyTest.PctChange[plotdat$SPWeeklyTest.PctChange < 0]), lty = 2, col = "red")
  abline(h = mean(plotdat$SPWeeklyTest.PctChange[plotdat$SPWeeklyTest.PctChange > 0]), lty = 2, col = "green")
  text(x = rep(-8, 3)[j], y = rep(15, 3)[j], labels = c("Model 1", "Model 5", "Model 6")[j], adj = 0)
  text(x = rep(110, 3)[j], y = rep(15, 3)[j], labels = as.numeric(table(plotdat$SPWeeklyTest.Direction)[1]),
       col = "red", adj = 0)
  text(x = rep(140, 3)[j], y = rep(15, 3)[j], labels = "/", adj = 0)
  text(x = rep(150, 3)[j], y = rep(15, 3)[j], labels = as.numeric(table(plotdat$SPWeeklyTest.Direction)[2]),
       col = "green", adj = 0)}

```

``` {r Figure30, fig.height = 7.8, warning = FALSE, fig.cap = "\\label{fig:Figure30} Relative value of the S\\&P 500 from 2011-2021 (left) and percent change for weeks in 2011-2021 for which an increase was not predicted (right) based on QDA models fit to the 1986-2010 data; the three models here were selected using accuracy. The black line represents a buy-and-hold strategy, while the blue line represents a strategy of selling all assets before a predicted decrease and then purchasing them back the next time there is a predicted increase. The purple line represents a less risky strategy of only selling 35\\% of assets before a predicted decrease and then purchasing them back the next time there is a predicted increase."}

# Generate plots
par(mfrow = c(3, 2), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
for(i in c(2, 7, 8)){
  
  # Offset numbers for indexing purposes
  if(i == 2){j <- 1}
  if(i == 7){j <- 2}
  if(i == 8){j <- 3}
  
  # Plot returns
  plot(returns.damod(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest, daType = "qda"), type = "l",
       col = "blue", xaxt = "n", xlab = "Year", ylab = "Proportion of Initial Value", ylim = c(0, 8))
  axis(1, at = nrow(SPWeeklyTest)*(0:5)/5, labels = seq(2011, 2021, length.out = 6), cex.axis = 0.85)
  lines(returns.damod(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest, daType = "qda", lrisk = TRUE), col = "purple")
  lines(returns.damod("none", data = SPWeeklyTest))
  text(x = rep(-8, 3)[j], y = rep(7.8, 3)[j], labels = c("Model 2", "Model 7", "Model 8")[j], adj = 0)
  
  # Plot increases/decreases on weeks when mode predicts a decrease
  da.fit <- qda(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest)
  da.pred <- predict(da.fit, SPWeeklyTest)$class
  plotdat <- data.frame(da.pred, SPWeeklyTest$Direction, SPWeeklyTest$PctChange)
  plotdat <- subset(plotdat, da.pred == "Down")
  plot(as.numeric(rownames(plotdat)), plotdat$SPWeeklyTest.PctChange, pch = 16, xaxt = "n",
       xlim = c(0, nrow(SPWeeklyTest)), col = ifelse(plotdat$SPWeeklyTest.PctChange < 0, "red", "green"),
       xlab = "Year", ylab = "Weekly Percent Change", ylim = c(-16, 16), cex.axis = 0.9)
  axis(1, at = nrow(SPWeeklyTest)*(0:5)/5, labels = seq(2011, 2021, length.out = 6), cex.axis = 0.85)
  abline(h = mean(plotdat$SPWeeklyTest.PctChange[plotdat$SPWeeklyTest.PctChange < 0]), lty = 2, col = "red")
  abline(h = mean(plotdat$SPWeeklyTest.PctChange[plotdat$SPWeeklyTest.PctChange > 0]), lty = 2, col = "green")
  text(x = rep(-8, 3)[j], y = rep(15, 3)[j], labels = c("Model 2", "Model 7", "Model 8")[j], adj = 0)
  text(x = rep(110, 3)[j], y = rep(15, 3)[j], labels = as.numeric(table(plotdat$SPWeeklyTest.Direction)[1]),
       col = "red", adj = 0)
  text(x = c(140, 155, 155)[j], y = rep(15, 3)[j], labels = "/", adj = 0)
  text(x = c(150, 165, 165)[j], y = rep(15, 3)[j], labels = as.numeric(table(plotdat$SPWeeklyTest.Direction)[2]),
       col = "green", adj = 0)}

```

``` {r Figure31, fig.height = 7.8, warning = FALSE, fig.cap = "\\label{fig:Figure31} Relative value of the S\\&P 500 from 2011-2021 (left) and percent change for weeks in 2011-2021 for which an increase was not predicted (right) based on LDA models fit to the 1986-2010 data; the three models here were selected using PPV. The black line represents a buy-and-hold strategy, while the blue line represents a strategy of selling all assets before a predicted decrease and then purchasing them back the next time there is a predicted increase. The purple line represents a less risky strategy of only selling 35\\% of assets before a predicted decrease and then purchasing them back the next time there is a predicted increase."}

# Generate plots
par(mfrow = c(3, 2), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
for(i in c(3, 9, 10)){
  
  # Offset numbers for indexing purposes
  if(i == 3){j <- 1}
  if(i == 9){j <- 2}
  if(i == 10){j <- 3}
  
  # Plot returns
  plot(returns.damod(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest, daType = "lda"), type = "l",
       col = "blue", xaxt = "n", xlab = "Year", ylab = "Proportion of Initial Value", ylim = c(0, 8))
  axis(1, at = nrow(SPWeeklyTest)*(0:5)/5, labels = seq(2011, 2021, length.out = 6), cex.axis = 0.85)
  lines(returns.damod(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest, daType = "lda", lrisk = TRUE), col = "purple")
  lines(returns.damod("none", data = SPWeeklyTest))
  text(x = rep(-8, 3)[j], y = rep(7.8, 3)[j], labels = c("Model 3", "Model 9", "Model 10")[j], adj = 0)
  
  # Plot increases/decreases on weeks when mode predicts a decrease
  da.fit <- lda(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest)
  da.pred <- predict(da.fit, SPWeeklyTest)$class
  plotdat <- data.frame(da.pred, SPWeeklyTest$Direction, SPWeeklyTest$PctChange)
  plotdat <- subset(plotdat, da.pred == "Down")
  plot(as.numeric(rownames(plotdat)), plotdat$SPWeeklyTest.PctChange, pch = 16, xaxt = "n",
       xlim = c(0, nrow(SPWeeklyTest)), col = ifelse(plotdat$SPWeeklyTest.PctChange < 0, "red", "green"),
       xlab = "Year", ylab = "Weekly Percent Change", ylim = c(-16, 16), cex.axis = 0.9)
  axis(1, at = nrow(SPWeeklyTest)*(0:5)/5, labels = seq(2011, 2021, length.out = 6), cex.axis = 0.85)
  abline(h = mean(plotdat$SPWeeklyTest.PctChange[plotdat$SPWeeklyTest.PctChange < 0]), lty = 2, col = "red")
  abline(h = mean(plotdat$SPWeeklyTest.PctChange[plotdat$SPWeeklyTest.PctChange > 0]), lty = 2, col = "green")
  text(x = rep(-8, 3)[j], y = rep(15, 3)[j], labels = c("Model 3", "Model 9", "Model 10")[j], adj = 0)
  text(x = c(110, 110, 125)[j], y = rep(15, 3)[j], labels = as.numeric(table(plotdat$SPWeeklyTest.Direction)[1]),
       col = "red", adj = 0)
  text(x = c(140, 140, 156)[j], y = rep(15, 3)[j], labels = "/", adj = 0)
  text(x = c(150, 150, 165)[j], y = rep(15, 3)[j], labels = as.numeric(table(plotdat$SPWeeklyTest.Direction)[2]),
       col = "green", adj = 0)}

```

``` {r Figure32, fig.height = 7.8, warning = FALSE, fig.cap = "\\label{fig:Figure32} Relative value of the S\\&P 500 from 2011-2021 (left) and percent change for weeks in 2011-2021 for which an increase was not predicted (right) based on QDA models fit to the 1986-2010 data; the three models here were selected using PPV. The black line represents a buy-and-hold strategy, while the blue line represents a strategy of selling all assets before a predicted decrease and then purchasing them back the next time there is a predicted increase. The purple line represents a less risky strategy of only selling 35\\% of assets before a predicted decrease and then purchasing them back the next time there is a predicted increase."}

# Generate plots
par(mfrow = c(3, 2), mar = c(5, 4, 0.2, 2) + 0.1, mgp = c(2.3, 0.6, 0))
for(i in c(4, 11, 12)){
  
  # Offset numbers for indexing purposes
  if(i == 4){j <- 1}
  if(i == 11){j <- 2}
  if(i == 12){j <- 3}
  
  # Plot returns
  plot(returns.damod(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest, daType = "qda"), type = "l",
       col = "blue", xaxt = "n", xlab = "Year", ylab = "Proportion of Initial Value", ylim = c(0, 8))
  axis(1, at = nrow(SPWeeklyTest)*(0:5)/5, labels = seq(2011, 2021, length.out = 6), cex.axis = 0.85)
  lines(returns.damod(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest, daType = "qda", lrisk = TRUE), col = "purple")
  lines(returns.damod("none", data = SPWeeklyTest))
  text(x = rep(-8, 3)[j], y = rep(7.8, 3)[j], labels = c("Model 4", "Model 11", "Model 12")[j], adj = 0)
  
  # Plot increases/decreases on weeks when mode predicts a decrease
  da.fit <- qda(formula(SPWeeklyDMod[[i]]), data = SPWeeklyTest)
  da.pred <- predict(da.fit, SPWeeklyTest)$class
  plotdat <- data.frame(da.pred, SPWeeklyTest$Direction, SPWeeklyTest$PctChange)
  plotdat <- subset(plotdat, da.pred == "Down")
  plot(as.numeric(rownames(plotdat)), plotdat$SPWeeklyTest.PctChange, pch = 16, xaxt = "n",
       xlim = c(0, nrow(SPWeeklyTest)), col = ifelse(plotdat$SPWeeklyTest.PctChange < 0, "red", "green"),
       xlab = "Year", ylab = "Weekly Percent Change", ylim = c(-16, 16), cex.axis = 0.9)
  axis(1, at = nrow(SPWeeklyTest)*(0:5)/5, labels = seq(2011, 2021, length.out = 6), cex.axis = 0.85)
  abline(h = mean(plotdat$SPWeeklyTest.PctChange[plotdat$SPWeeklyTest.PctChange < 0]), lty = 2, col = "red")
  abline(h = mean(plotdat$SPWeeklyTest.PctChange[plotdat$SPWeeklyTest.PctChange > 0]), lty = 2, col = "green")
  text(x = rep(-8, 3)[j], y = rep(15, 3)[j], labels = c("Model 4", "Model 11", "Model 12")[j], adj = 0)
  text(x = c(110, 125, 125)[j], y = rep(15, 3)[j], labels = as.numeric(table(plotdat$SPWeeklyTest.Direction)[1]),
       col = "red", adj = 0)
  text(x = c(140, 170, 170)[j], y = rep(15, 3)[j], labels = "/", adj = 0)
  text(x = c(150, 180, 180)[j], y = rep(15, 3)[j], labels = as.numeric(table(plotdat$SPWeeklyTest.Direction)[2]),
       col = "green", adj = 0)}

```

\newpage

## K-Nearest Neighbours

## Support Vector Machines

# Predictive Analysis: NASDAQ Composite

## Logistic Regression

## Discriminant Analysis

## K-Nearest Neighbours

## Support Vector Machines

# Predictive Analysis: Dow Jones Industrial Average

## Logistic Regression

## Discriminant Analysis

## K-Nearest Neighbours

## Support Vector Machines

# Conclusions
